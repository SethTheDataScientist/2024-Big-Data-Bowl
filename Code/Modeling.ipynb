{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from scipy.stats import multivariate_normal\n",
    "import scipy.stats as stats\n",
    "import scipy\n",
    "import math\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the relative path to the data directory\n",
    "non_games_data_folder_path = \"insert path\"\n",
    "# List all files in the data folder\n",
    "file_list_non_games = os.listdir(non_games_data_folder_path)\n",
    "\n",
    "# Use glob to filter specific file types\n",
    "csv_files_non_games = glob.glob(os.path.join(non_games_data_folder_path, \"*.csv\"))\n",
    "\n",
    "\n",
    "# Read in the supplementary data\n",
    "games = pd.read_csv(csv_files_non_games[0])\n",
    "nfl_colors = pd.read_csv(csv_files_non_games[1])\n",
    "players = pd.read_csv(csv_files_non_games[2])\n",
    "plays = pd.read_csv(csv_files_non_games[3])\n",
    "tackles = pd.read_csv(csv_files_non_games[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ModelingDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sethl\\AppData\\Local\\Temp\\ipykernel_17372\\1690626378.py:1: DtypeWarning: Columns (45,61,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ModelingDF = pd.read_csv(\"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Created_DF/WorkDF.csv\")\n"
     ]
    }
   ],
   "source": [
    "ModelingDF = pd.read_csv(\"insert path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voronoi Tesselations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def custom_scaling_factor(value):\n",
    "    if value == 0:\n",
    "        return 0\n",
    "    elif 1 <= value <= 6:\n",
    "        return np.exp(value - 6)\n",
    "    elif value > 6:\n",
    "        return np.log(value + 1) / np.log(6)\n",
    "\n",
    "def count_matching_rows(df):\n",
    "    counts = []\n",
    "    target = 7.5\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if row[\"distanceFromBall\"] <= target:\n",
    "            counts.append(1)\n",
    "        else:\n",
    "            counts.append(0)\n",
    "    return sum(counts) \n",
    "\n",
    "def Calculate_Voronoi(playerCoordinates = []):    \n",
    "    \n",
    "    playerCoordinates[\"UniqueIndex\"] = playerCoordinates[\"gameId\"].astype(str) + \"-\" + playerCoordinates['playId'].astype(str) + \"-\" + playerCoordinates['frameId'].astype(str)\n",
    "\n",
    "    TotalVoronoi = pd.DataFrame()\n",
    "\n",
    "    unique_frames = playerCoordinates['UniqueIndex'].unique()\n",
    "\n",
    "    output_df = pd.DataFrame()\n",
    "\n",
    "    for frame in unique_frames:\n",
    "\n",
    "        frame_data = playerCoordinates[playerCoordinates[\"UniqueIndex\"] == frame]\n",
    "\n",
    "        frame_data = frame_data[(frame_data[\"club\"] == frame_data['defensiveTeam']) |\n",
    "                                            (frame_data[\"GotTheBall\"] == 1)]\n",
    "        \n",
    "        frame_data.sort_values(by=['gameId', 'playId', 'nflId', 'frameId'], inplace=True)\n",
    "        \n",
    "        xCoordinateBall=frame_data.loc[(frame_data[\"GotTheBall\"] == 1)]['x'].unique()[0]\n",
    "        yCoordinateBall=frame_data.loc[(frame_data[\"GotTheBall\"] == 1)]['y'].unique()[0]\n",
    "        frame_data['distanceFromBall']=((frame_data['x']-xCoordinateBall)**2 + \\\n",
    "                                         (frame_data['y']-yCoordinateBall)**2)**(1/2)\n",
    "        \n",
    "\n",
    "        bounding_lowerL = {'x' : min(frame_data['x'].min() - 1, 0),\n",
    "                            'y' : min(frame_data['y'].min() - 1, 0)} \n",
    "        bounding_upperL = {'x' : max(frame_data['x'].max() + 1, 120),\n",
    "                            'y' : max(frame_data['y'].max() + 1, 53.3)}\n",
    "        bounding_lowerR = {'x' : min(frame_data['x'].min() - 1, 0),\n",
    "                            'y' : max(frame_data['y'].max() + 1, 53.3)}\n",
    "        bounding_upperR = {'x' : max(frame_data['x'].max() + 1, 120),\n",
    "                            'y' : min(frame_data['y'].min() - 1, 0)}\n",
    "\n",
    "        bounding_lowerL = pd.DataFrame([bounding_lowerL])\n",
    "        bounding_upperL = pd.DataFrame([bounding_upperL])\n",
    "        bounding_lowerR = pd.DataFrame([bounding_lowerR])\n",
    "        bounding_upperR = pd.DataFrame([bounding_upperR])\n",
    "\n",
    "\n",
    "        frame_data = pd.concat([frame_data, bounding_lowerL], ignore_index=True)\n",
    "        frame_data = pd.concat([frame_data, bounding_upperL], ignore_index=True)\n",
    "        frame_data = pd.concat([frame_data, bounding_lowerR], ignore_index=True)\n",
    "        frame_data = pd.concat([frame_data, bounding_upperR], ignore_index=True)\n",
    "\n",
    "        frame_data[\"DefendersWithin\"] = count_matching_rows(frame_data)\n",
    "\n",
    "        points = frame_data[['x', 'y']].dropna().values\n",
    "\n",
    "        # Create a Voronoi diagram\n",
    "        vor = Voronoi(points)\n",
    "\n",
    "        # Iterate through the input points\n",
    "        for i, point in enumerate(points):\n",
    "            # Find the Voronoi region index for the current point\n",
    "            region_index = vor.point_region[i]\n",
    "            \n",
    "            # Get the vertices of the region\n",
    "            region_vertices = vor.regions[region_index]\n",
    "            \n",
    "            # Filter out invalid vertices\n",
    "            region_vertices = [vertex for vertex in region_vertices if vertex != -1]\n",
    "            \n",
    "            if len(region_vertices) > 0:\n",
    "                # Get the vertices of the region\n",
    "                vertices = vor.vertices[region_vertices]\n",
    "                \n",
    "                # Calculate the area using the Shoelace formula\n",
    "                area = 0.5 * np.abs(np.dot(vertices[:, 0], np.roll(vertices[:, 1], 1)) -\n",
    "                                np.dot(vertices[:, 1], np.roll(vertices[:, 0], 1)))\n",
    "                \n",
    "                # Store the area in the 'area' column of VOR_df for the current point\n",
    "                frame_data.at[i, 'area'] = area\n",
    "\n",
    "            closest_frame_df = frame_data[(frame_data[\"distanceFromBall\"] <= 10) &\n",
    "                                 (frame_data[\"club\"] == frame_data[\"defensiveTeam\"])][[\"gameId\", \"playId\", \"frameId\", \"nflId\"]]\n",
    "\n",
    "\n",
    "        TotalVoronoi = pd.concat([TotalVoronoi, frame_data], ignore_index=True) \n",
    "\n",
    "        TotalVoronoi.dropna(subset = [\"gameId\"], inplace = True)\n",
    "\n",
    "        output_df = pd.concat([output_df, closest_frame_df], ignore_index=True) \n",
    "\n",
    "\n",
    "        TotalVoronoi = TotalVoronoi[TotalVoronoi[\"GotTheBall\"] == 1]\n",
    "\n",
    "        TotalVoronoi[\"ScalingFactor\"] = TotalVoronoi[\"DefendersWithin\"].apply(custom_scaling_factor)\n",
    "\n",
    "        TotalVoronoi['adjusted_change'] = TotalVoronoi['area'] * TotalVoronoi[\"PercentRankA\"] * \\\n",
    "                                            TotalVoronoi[\"ScalingFactor\"]\n",
    "\n",
    "    return (TotalVoronoi, output_df)\n",
    "\n",
    "WorkDF_data_folder_path = \"insert path\"\n",
    "\n",
    "# List all files in the data folder\n",
    "WorkDF_file_list = os.listdir(WorkDF_data_folder_path)\n",
    "\n",
    "# Use glob to filter specific file types\n",
    "WorkDF_csv_files = glob.glob(os.path.join(WorkDF_data_folder_path, \"*.csv\"))\n",
    "\n",
    "\n",
    "for game in WorkDF_csv_files:\n",
    "    # Your code to process the chunk\n",
    "    VOR_df = pd.read_csv(game)\n",
    "\n",
    "    gameName = VOR_df[\"gameId\"].unique()\n",
    "\n",
    "    VOR_df_output, closest_df = Calculate_Voronoi(VOR_df)    \n",
    "\n",
    "    vor_filepath = \"insert path\"\n",
    "    vor_filename = f\"VoronoiChunk{gameName}.csv\"\n",
    "    \n",
    "    # Save the processed chunk to a specific location\n",
    "    VOR_df_output.to_csv(f\"{vor_filepath}{vor_filename}\", index=False)\n",
    "\n",
    "    \n",
    "    closest_filepath = \"insert path\"\n",
    "    closest_filename = f\"ClosestChunk{gameName}.csv\"\n",
    "    \n",
    "    # Save the processed chunk to a specific location\n",
    "    closest_df.to_csv(f\"{closest_filepath}{closest_filename}\", index=False)\n",
    "\n",
    "    del VOR_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vor_filepath = \"insert path\"\n",
    "# List all files in the data folder\n",
    "vor_file_list = os.listdir(vor_filepath)\n",
    "\n",
    "# Use glob to filter specific file types\n",
    "vor_csv_files = glob.glob(os.path.join(vor_filepath, \"*.csv\"))\n",
    "\n",
    "# Read in the weekly game data and concat into one combined df\n",
    "vor_dfs = [pd.read_csv(file) for file in vor_csv_files]\n",
    "VOR_df_output = pd.concat(vor_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(VOR_df_output[\"distanceFromBall\"].mean())\n",
    "print(VOR_df_output[\"area\"].mean())\n",
    "print(VOR_df_output[\"adjusted_change\"].mean())\n",
    "print(VOR_df_output[\"DefendersWithin\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Min_Play_Count = 15\n",
    "\n",
    "ExtraWork = VOR_df_output.copy()\n",
    "\n",
    "# Group by 'nflId' and count the unique 'frameId' values in each group\n",
    "play_counts = ExtraWork.groupby('nflId')['playId'].nunique()\n",
    "\n",
    "# Create a new column 'TotalPlays' in the original DataFrame\n",
    "ExtraWork['TotalPlays'] = ExtraWork['nflId'].map(play_counts)\n",
    "ExtraWork = ExtraWork[ExtraWork[\"TotalPlays\"] >= Min_Play_Count]\n",
    "\n",
    "Summarized = pd.DataFrame()\n",
    "Summarized[\"MeanPlay\"] = ExtraWork.groupby([\"nflId\"])[\"adjusted_change\"].mean()\n",
    "Summarized[\"MeanDefenders\"] = ExtraWork.groupby([\"nflId\"])[\"DefendersWithin\"].mean()\n",
    "Summarized = Summarized.drop_duplicates()\n",
    "Summarized.reset_index(inplace=True)\n",
    "\n",
    "Summarized = Summarized.sort_values(by=['MeanPlay'], ascending = False)\n",
    "\n",
    "player_name = players[[\"nflId\", \"position\", \"displayName\"]]\n",
    "\n",
    "Summarized = pd.merge(Summarized, player_name, on = \"nflId\")\n",
    "\n",
    "TotalPlays = ExtraWork[[\"nflId\", \"club\", \"TotalPlays\"]].drop_duplicates()\n",
    "\n",
    "Summarized = pd.merge(Summarized, TotalPlays, on = \"nflId\")\n",
    "Summarized = Summarized.drop_duplicates()\n",
    "\n",
    "EPA = plays.groupby([\"ballCarrierId\"])[\"expectedPointsAdded\"].mean()\n",
    "\n",
    "Summarized = pd.merge(Summarized, EPA, left_on=\"nflId\", right_on=\"ballCarrierId\")\n",
    "\n",
    "Summarized = Summarized.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOR_df_output.to_csv(\"insert path\", index=False)\n",
    "Summarized.to_csv(\"insert path\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defensive Closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_filepath = \"insert path\"\n",
    "# List all files in the data folder\n",
    "closest_file_list = os.listdir(closest_filepath)\n",
    "\n",
    "# Use glob to filter specific file types\n",
    "closest_csv_files = glob.glob(os.path.join(closest_filepath, \"*.csv\"))\n",
    "\n",
    "# Read in the weekly game data and concat into one combined df\n",
    "closest_dfs = [pd.read_csv(file) for file in closest_csv_files]\n",
    "closest_df = pd.concat(closest_dfs, ignore_index=True)\n",
    "\n",
    "VOR_df_output = pd.read_csv(\"insert path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ClosestPlayersWork = pd.merge(VOR_df_output, closest_df, on = [\"gameId\", \"playId\", \"frameId\"])\n",
    "\n",
    "# Group by 'nflId' and count the unique 'frameId' values in each group\n",
    "play_counts = ClosestPlayersWork.groupby('nflId_y')['playId'].nunique()\n",
    "\n",
    "# Create a new column 'TotalPlays' in the original DataFrame\n",
    "ClosestPlayersWork['TotalPlays'] = ClosestPlayersWork['nflId_y'].map(play_counts)\n",
    "ClosestPlayersWork = ClosestPlayersWork[ClosestPlayersWork[\"TotalPlays\"] >= 15]\n",
    "\n",
    "\n",
    "ClosestSummary = pd.DataFrame()\n",
    "\n",
    "ClosestSummary[\"PassVoronoi\"] = ClosestPlayersWork[ClosestPlayersWork[\"PassPlay\"] == 1].groupby('nflId_y')[\"adjusted_change\"].mean()\n",
    "\n",
    "ClosestSummary[\"RushVoronoi\"] = ClosestPlayersWork[ClosestPlayersWork[\"PassPlay\"] == 0].groupby('nflId_y')[\"adjusted_change\"].mean()\n",
    "\n",
    "ClosestSummary[\"TotalVoronoi\"] = ClosestPlayersWork.groupby('nflId_y')[\"adjusted_change\"].mean()\n",
    "\n",
    "\n",
    "\n",
    "ClosestSummary = ClosestSummary.drop_duplicates()\n",
    "ClosestSummary.reset_index(inplace=True)\n",
    "TotalPlaysClosest = ClosestPlayersWork[[\"nflId_y\", \"defensiveTeam\", \"TotalPlays\"]].drop_duplicates()\n",
    "\n",
    "ClosestSummary = pd.merge(ClosestSummary, TotalPlaysClosest, on = \"nflId_y\")\n",
    "\n",
    "ClosestSummary = pd.merge(ClosestSummary, player_name, left_on = \"nflId_y\", right_on = \"nflId\")\n",
    "\n",
    "PlayerSingleName = players[[\"nflId\", \"displayName\"]].drop_duplicates()\n",
    "\n",
    "ClosestSummary = pd.merge(ClosestSummary, PlayerSingleName, left_on = \"nflId_y\", right_on = \"nflId\")\n",
    "\n",
    "ClosestSummary = ClosestSummary.rename(columns={'nflId_y': 'nflId'})\n",
    "ClosestSummary = ClosestSummary[[\"nflId\", 'displayName', 'position',\n",
    "                                  'displayName', 'defensiveTeam',\n",
    "                                 'TotalPlays',\n",
    "                                 \"PassVoronoi\", 'RushVoronoi', 'TotalVoronoi']]\n",
    "ClosestSummary = ClosestSummary.sort_values(by=['TotalVoronoi'], ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_df.to_csv(\"insert path\", index=False)\n",
    "ClosestSummary.to_csv(\"insert path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Voronoi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOR_df_output = pd.read_csv(\"insert path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DefensiveVoronoiWork = VOR_df_output.copy()\n",
    "\n",
    "\n",
    "DefensiveVoronoi = pd.DataFrame()\n",
    "DefensiveVoronoi[\"PassVoroni\"] = DefensiveVoronoiWork[DefensiveVoronoiWork[\"PassPlay\"] == 1].groupby(\"defensiveTeam\")[\"adjusted_change\"].mean()\n",
    "DefensiveVoronoi[\"RushVoronoi\"] = DefensiveVoronoiWork[DefensiveVoronoiWork[\"PassPlay\"] == 0].groupby(\"defensiveTeam\")[\"adjusted_change\"].mean()\n",
    "DefensiveVoronoi[\"TotalVoronoi\"] = DefensiveVoronoiWork.groupby(\"defensiveTeam\")[\"adjusted_change\"].mean()\n",
    "DefensiveVoronoi = DefensiveVoronoi.drop_duplicates()\n",
    "DefensiveVoronoi.reset_index(inplace=True)\n",
    "\n",
    "DefensiveVoronoi = DefensiveVoronoi.sort_values(by=['TotalVoronoi'], ascending = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DefensiveVoronoi.to_csv(\"insert path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break Through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaxSpeed = pd.DataFrame(ModelingDF.groupby('nflId')['s'].max())\n",
    "MaxSpeed['MaxS'] = np.where(MaxSpeed['s'] >= 15, 15, MaxSpeed['s'])\n",
    "MaxSpeed.drop(\"s\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rows_above_threshold(array, threshold=1e-3):\n",
    "    max_values = np.amax(array, axis=1)  # Get maximum values for each row\n",
    "    above_threshold = max_values > threshold\n",
    "    first_index = np.argmax(above_threshold)\n",
    "    last_index = len(above_threshold) - np.argmax(above_threshold[::-1]) - 1\n",
    "    return first_index.astype(int), last_index.astype(int)\n",
    "\n",
    "def find_columns_above_threshold(array, threshold=1e-3):\n",
    "    max_values = np.amax(array, axis=0)  # Get maximum values for each column\n",
    "    above_threshold = max_values > threshold\n",
    "    first_index = np.argmax(above_threshold)\n",
    "    last_index = len(above_threshold) - np.argmax(above_threshold[::-1]) - 1\n",
    "    return first_index.astype(int), last_index.astype(int)\n",
    "\n",
    "def uncovered_frame_list(row):\n",
    "    Ball_min_y = row[\"Ball_Min_y\"]\n",
    "    Ball_Max_y = row[\"Ball_Max_y\"]\n",
    "    Player_Min_y = row[\"Min_y\"]\n",
    "    Player_Max_y = row[\"Max_y\"]\n",
    "    \n",
    "    Ball_min_x = row[\"Ball_Min_x\"]\n",
    "    Ball_Max_x = row[\"Ball_Max_x\"]\n",
    "    Player_Min_x = row[\"Min_x\"]\n",
    "    Player_Max_x = row[\"Max_x\"]\n",
    "\n",
    "    Ball_Carrier = row['GotTheBall']\n",
    "    \n",
    "    condition = np.all((Player_Min_y <= Ball_min_y) & \\\n",
    "                        (Player_Max_y >= Ball_Max_y) & \\\n",
    "                          (Player_Max_x >=  Ball_Max_x) & \\\n",
    "                            (Ball_Carrier != 1))\n",
    "    \n",
    "    return 1 if condition else 0\n",
    "\n",
    "def CalculateBreakthrough(playerCoordinates=[]):\n",
    "\n",
    "  np.random.seed(42)\n",
    "  \n",
    "  #Determined each speed in x and y, as well as distance from the QB\n",
    "  # Filter rows where 'GotTheBall' is 1\n",
    "  ball_data = playerCoordinates[playerCoordinates[\"GotTheBall\"] == 1]\n",
    "\n",
    "  # Calculate x and y coordinates of the ball for each play and frame\n",
    "  ball_data = ball_data.groupby([\"playId\", \"frameId\"]).agg({'clean_x': 'unique', 'clean_y': 'unique'}).reset_index()\n",
    "\n",
    "  # Merge these coordinates back into the original DataFrame\n",
    "  playerCoordinates = playerCoordinates.merge(ball_data, on=[\"playId\", \"frameId\"], suffixes=('', '_Ball'), how='left')\n",
    "\n",
    "  # Calculate the distance from the ball\n",
    "  playerCoordinates['distanceFromBall'] = (\n",
    "      (playerCoordinates['clean_x'] - playerCoordinates['clean_x_Ball'])**2 +\n",
    "      (playerCoordinates['clean_y'] - playerCoordinates['clean_y_Ball'])**2\n",
    "  )**(1/2)\n",
    "  \n",
    "  playerCoordinates['distanceFromBall'] = np.where(playerCoordinates['distanceFromBall'] == 0, 1.5, playerCoordinates['distanceFromBall']).astype(float)\n",
    "\n",
    "  playerCoordinates['PartOfPlay'] = playerCoordinates.groupby(['playId','nflId'])['distanceFromBall'].transform(lambda x: (x <= 10).any()).astype(int)\n",
    "  \n",
    "  playerCoordinates['radiansDirection'] = playerCoordinates['clean_dir'].astype(float).apply(math.radians) #Converts angle in degrees to radians\n",
    "  playerCoordinates['xComponent']=playerCoordinates['radiansDirection'].astype(float).apply(math.cos) #Converts angle into an x and y component\n",
    "  playerCoordinates['yComponent']=playerCoordinates['radiansDirection'].astype(float).apply(math.sin)\n",
    "  playerCoordinates['xspeed']=playerCoordinates['xComponent']*playerCoordinates['s'] #Determines magnitude of speed by multiplying x and y component by magnitude of speed\n",
    "  playerCoordinates['yspeed']=playerCoordinates['yComponent']*playerCoordinates['s']\n",
    "  playerCoordinates['xComponent']= np.where((playerCoordinates['xComponent'] < 1e-2) & \n",
    "                                            (playerCoordinates['xComponent'] > -1e-2), 1e-2, playerCoordinates['xComponent'])\n",
    "  playerCoordinates['yComponent']= np.where((playerCoordinates['yComponent'] < 1e-2) & \n",
    "                                            (playerCoordinates['yComponent'] > -1e-2), 1e-2, playerCoordinates['yComponent'])\n",
    "\n",
    "\n",
    "  \n",
    "  playerCoordinates[\"UniqueIndex\"] = playerCoordinates[\"gameId\"].astype(str) + \"-\" + playerCoordinates['playId'].astype(str) + \"-\" + playerCoordinates['frameId'].astype(str)\n",
    "\n",
    "  unique_frames = playerCoordinates['UniqueIndex'].unique()\n",
    "\n",
    "  output_df = pd.DataFrame()\n",
    "  \n",
    "  y, x = np.mgrid[0:53.3:1, 0:120:1]\n",
    "  locations = np.dstack((x, y))\n",
    "  \n",
    "  for frame in unique_frames:\n",
    "\n",
    "    frame_data = playerCoordinates[playerCoordinates[\"UniqueIndex\"] == frame]\n",
    "    frame_list = []\n",
    "\n",
    "    frame_data = frame_data[((frame_data[\"PartOfPlay\"] == 1) & (frame_data[\"club\"] == frame_data[\"defensiveTeam\"])) |  \n",
    "                                        (frame_data[\"GotTheBall\"] == 1)]\n",
    "\n",
    "    # Generate pdf's for the defensive players and the quarteback\n",
    "    for index, row in frame_data.iterrows():\n",
    "      if((row['club'] == row['defensiveTeam'])) | (row[\"GotTheBall\"] == 1):\n",
    "        speed_Ratio=(row['s']**2)/(row[\"MaxS\"]**2)\n",
    "        topLeftSMatrix=(row['distanceFromBall']+row['distanceFromBall']*speed_Ratio)/2\n",
    "        bottomRightSMatrix=(row['distanceFromBall']-row['distanceFromBall']*speed_Ratio)/2\n",
    "\n",
    "        try:\n",
    "          #Setting up R and S matrix in bivariate normal distribution\n",
    "          r_matrix=[(row['xComponent'], -row['yComponent']),(row['yComponent'], row['xComponent'])]\n",
    "          r_matrix=pd.DataFrame(data=r_matrix)\n",
    "          #Adds very small value to ensure matrix is invertible even if player is completely stationary\n",
    "          s_matrix=[(topLeftSMatrix+0.00001,0), (0, bottomRightSMatrix-0.000001)]\n",
    "          s_matrix=pd.DataFrame(data=s_matrix)\n",
    "          inverse_r_Matrix=np.linalg.inv(r_matrix)\n",
    "          multiplyingTogetherFirstTwoMatrices=r_matrix.dot(s_matrix)\n",
    "          nextMatrix=multiplyingTogetherFirstTwoMatrices.dot(s_matrix)\n",
    "          covariance_matrix=nextMatrix.dot(inverse_r_Matrix)\n",
    "          mu_val_x=row['clean_x']+row['xspeed']*0.5\n",
    "          mu_val_y=row['clean_y']+row['yspeed']*0.5\n",
    "          mu=[mu_val_x,mu_val_y]\n",
    "          player_pdf=multivariate_normal(mu,covariance_matrix).pdf(locations)\n",
    "\n",
    "          Player_y_max = find_rows_above_threshold(player_pdf)\n",
    "\n",
    "          Player_x_max = find_columns_above_threshold(player_pdf)\n",
    "\n",
    "          frame_data.at[index, \"Max_y\"] = int(Player_y_max[1])\n",
    "          frame_data.at[index, \"Min_y\"] = int(Player_y_max[0])\n",
    "\n",
    "          frame_data.at[index, \"Max_x\"] = int(Player_x_max[1])\n",
    "          frame_data.at[index, \"Min_x\"] = int(Player_x_max[0])\n",
    "\n",
    "          frame_data[\"Max_y\"] = frame_data[\"Max_y\"].fillna(0)\n",
    "          frame_data[\"Min_y\"] = frame_data[\"Min_y\"].fillna(53) \n",
    "\n",
    "          frame_data[\"Max_x\"] = frame_data[\"Max_x\"].fillna(0)\n",
    "          frame_data[\"Min_x\"] = frame_data[\"Min_x\"].fillna(120) \n",
    "\n",
    "          \n",
    "        except np.linalg.LinAlgError:\n",
    "           pass\n",
    "\n",
    "    frame_data[\"Ball_Max_y\"] = frame_data.loc[frame_data[\"GotTheBall\"] == 1, \"Max_y\"].iloc[0].astype(int)\n",
    "    frame_data[\"Ball_Min_y\"] = frame_data.loc[frame_data[\"GotTheBall\"] == 1, \"Min_y\"].iloc[0].astype(int)\n",
    "    \n",
    "    frame_data[\"Ball_Max_x\"] = frame_data.loc[frame_data[\"GotTheBall\"] == 1, \"Max_x\"].iloc[0].astype(int)\n",
    "    frame_data[\"Ball_Min_x\"] = frame_data.loc[frame_data[\"GotTheBall\"] == 1, \"Min_x\"].iloc[0].astype(int)\n",
    "\n",
    "    frame_data[\"Covering\"] = frame_data.apply(uncovered_frame_list, axis=1)\n",
    "\n",
    "    output_df = pd.concat([output_df, frame_data], ignore_index=True)\n",
    "\n",
    "  \n",
    "  return output_df\n",
    "      \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sethl\\AppData\\Local\\Temp\\ipykernel_5676\\247374904.py:17: DtypeWarning: Columns (61) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  breakthrough_df = pd.read_csv(game)\n",
      "C:\\Users\\sethl\\AppData\\Local\\Temp\\ipykernel_5676\\4184700478.py:55: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  playerCoordinates['distanceFromBall'] = np.where(playerCoordinates['distanceFromBall'] == 0, 1.5, playerCoordinates['distanceFromBall']).astype(float)\n",
      "C:\\Users\\sethl\\AppData\\Local\\Temp\\ipykernel_5676\\247374904.py:17: DtypeWarning: Columns (61) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  breakthrough_df = pd.read_csv(game)\n",
      "C:\\Users\\sethl\\AppData\\Local\\Temp\\ipykernel_5676\\4184700478.py:55: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  playerCoordinates['distanceFromBall'] = np.where(playerCoordinates['distanceFromBall'] == 0, 1.5, playerCoordinates['distanceFromBall']).astype(float)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sethl\\OneDrive\\Important Stuff\\R\\R files\\NFL\\DataBowl\\2024-Big-Data-Bowl\\2024-Big-Data-Bowl\\Code\\Modeling.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sethl/OneDrive/Important%20Stuff/R/R%20files/NFL/DataBowl/2024-Big-Data-Bowl/2024-Big-Data-Bowl/Code/Modeling.ipynb#X31sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m gameName \u001b[39m=\u001b[39m breakthrough_df[\u001b[39m\"\u001b[39m\u001b[39mgameId\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39munique()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sethl/OneDrive/Important%20Stuff/R/R%20files/NFL/DataBowl/2024-Big-Data-Bowl/2024-Big-Data-Bowl/Code/Modeling.ipynb#X31sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Your code to process the chunk\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/sethl/OneDrive/Important%20Stuff/R/R%20files/NFL/DataBowl/2024-Big-Data-Bowl/2024-Big-Data-Bowl/Code/Modeling.ipynb#X31sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m breakthrough_df \u001b[39m=\u001b[39m CalculateBreakthrough(breakthrough_df)    \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sethl/OneDrive/Important%20Stuff/R/R%20files/NFL/DataBowl/2024-Big-Data-Bowl/2024-Big-Data-Bowl/Code/Modeling.ipynb#X31sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m filepath \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mC:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/BreakThroughChunks/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sethl/OneDrive/Important%20Stuff/R/R%20files/NFL/DataBowl/2024-Big-Data-Bowl/2024-Big-Data-Bowl/Code/Modeling.ipynb#X31sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m filename \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBreakThroughChunk\u001b[39m\u001b[39m{\u001b[39;00mgameName\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32mc:\\Users\\sethl\\OneDrive\\Important Stuff\\R\\R files\\NFL\\DataBowl\\2024-Big-Data-Bowl\\2024-Big-Data-Bowl\\Code\\Modeling.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/sethl/OneDrive/Important%20Stuff/R/R%20files/NFL/DataBowl/2024-Big-Data-Bowl/2024-Big-Data-Bowl/Code/Modeling.ipynb#X31sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m mu_val_y\u001b[39m=\u001b[39mrow[\u001b[39m'\u001b[39m\u001b[39mclean_y\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m+\u001b[39mrow[\u001b[39m'\u001b[39m\u001b[39myspeed\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m0.5\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/sethl/OneDrive/Important%20Stuff/R/R%20files/NFL/DataBowl/2024-Big-Data-Bowl/2024-Big-Data-Bowl/Code/Modeling.ipynb#X31sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m mu\u001b[39m=\u001b[39m[mu_val_x,mu_val_y]\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/sethl/OneDrive/Important%20Stuff/R/R%20files/NFL/DataBowl/2024-Big-Data-Bowl/2024-Big-Data-Bowl/Code/Modeling.ipynb#X31sZmlsZQ%3D%3D?line=108'>109</a>\u001b[0m player_pdf\u001b[39m=\u001b[39mmultivariate_normal(mu,covariance_matrix)\u001b[39m.\u001b[39;49mpdf(locations)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/sethl/OneDrive/Important%20Stuff/R/R%20files/NFL/DataBowl/2024-Big-Data-Bowl/2024-Big-Data-Bowl/Code/Modeling.ipynb#X31sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m Player_y_max \u001b[39m=\u001b[39m find_rows_above_threshold(player_pdf)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/sethl/OneDrive/Important%20Stuff/R/R%20files/NFL/DataBowl/2024-Big-Data-Bowl/2024-Big-Data-Bowl/Code/Modeling.ipynb#X31sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m Player_x_max \u001b[39m=\u001b[39m find_columns_above_threshold(player_pdf)\n",
      "File \u001b[1;32mc:\\Users\\sethl\\anaconda3\\envs\\S52\\lib\\site-packages\\scipy\\stats\\_multivariate.py:776\u001b[0m, in \u001b[0;36mmultivariate_normal_frozen.pdf\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpdf\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m--> 776\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mexp(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogpdf(x))\n",
      "File \u001b[1;32mc:\\Users\\sethl\\anaconda3\\envs\\S52\\lib\\site-packages\\scipy\\stats\\_multivariate.py:768\u001b[0m, in \u001b[0;36mmultivariate_normal_frozen.logpdf\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    766\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlogpdf\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    767\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dist\u001b[39m.\u001b[39m_process_quantiles(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim)\n\u001b[1;32m--> 768\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dist\u001b[39m.\u001b[39;49m_logpdf(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmean, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcov_info\u001b[39m.\u001b[39;49mU,\n\u001b[0;32m    769\u001b[0m                              \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcov_info\u001b[39m.\u001b[39;49mlog_pdet, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcov_info\u001b[39m.\u001b[39;49mrank)\n\u001b[0;32m    770\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mallow_singular \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcov_info\u001b[39m.\u001b[39mrank \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim):\n\u001b[0;32m    771\u001b[0m         out_of_bounds \u001b[39m=\u001b[39m \u001b[39m~\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcov_info\u001b[39m.\u001b[39m_support_mask(x\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean)\n",
      "File \u001b[1;32mc:\\Users\\sethl\\anaconda3\\envs\\S52\\lib\\site-packages\\scipy\\stats\\_multivariate.py:489\u001b[0m, in \u001b[0;36mmultivariate_normal_gen._logpdf\u001b[1;34m(self, x, mean, prec_U, log_det_cov, rank)\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Log of the multivariate normal probability density function.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \n\u001b[0;32m    467\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m \n\u001b[0;32m    487\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    488\u001b[0m dev \u001b[39m=\u001b[39m x \u001b[39m-\u001b[39m mean\n\u001b[1;32m--> 489\u001b[0m maha \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49msum(np\u001b[39m.\u001b[39;49msquare(np\u001b[39m.\u001b[39;49mdot(dev, prec_U)), axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    490\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m (rank \u001b[39m*\u001b[39m _LOG_2PI \u001b[39m+\u001b[39m log_det_cov \u001b[39m+\u001b[39m maha)\n",
      "File \u001b[1;32mc:\\Users\\sethl\\anaconda3\\envs\\S52\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2310\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[0;32m   2311\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[1;32m-> 2313\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49madd, \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out, keepdims\u001b[39m=\u001b[39;49mkeepdims,\n\u001b[0;32m   2314\u001b[0m                       initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[1;32mc:\\Users\\sethl\\anaconda3\\envs\\S52\\lib\\site-packages\\numpy\\core\\fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 88\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "WorkDF_data_folder_path = \"insert path\"\n",
    "# List all files in the data folder\n",
    "WorkDF_file_list = os.listdir(WorkDF_data_folder_path)\n",
    "\n",
    "# Use glob to filter specific file types\n",
    "WorkDF_csv_files = glob.glob(os.path.join(WorkDF_data_folder_path, \"*.csv\"))\n",
    "\n",
    "i = 0\n",
    "# for game in WorkDF_csv_files:\n",
    "while i < 1:\n",
    "\n",
    "    #Write code chunk to check if any of the files already in the folder are named what we want\n",
    "    #if so ignore it and move on to the next one\n",
    "\n",
    "\n",
    "    # Your code to process the chunk\n",
    "    breakthrough_df = pd.read_csv(game)\n",
    "\n",
    "    breakthrough_df = pd.merge(breakthrough_df, MaxSpeed, on= \"nflId\")\n",
    "\n",
    "    gameName = breakthrough_df[\"gameId\"].unique()\n",
    "\n",
    "    # Your code to process the chunk\n",
    "    breakthrough_df = CalculateBreakthrough(breakthrough_df)    \n",
    "\n",
    "    filepath = \"insert path\"\n",
    "    filename = f\"BreakThroughChunk{gameName}.csv\"\n",
    "    \n",
    "    # Save the processed chunk to a specific location\n",
    "    breakthrough_df.to_csv(f\"{filepath}{filename}\", index=False)\n",
    "\n",
    "    del breakthrough_df\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakthrough_filepath = \"insert path\"\n",
    "# List all files in the data folder\n",
    "BreakThrough_file_list = os.listdir(breakthrough_filepath)\n",
    "\n",
    "# Use glob to filter specific file types\n",
    "BreakThrough_csv_files = glob.glob(os.path.join(breakthrough_filepath, \"*.csv\"))\n",
    "\n",
    "#Breakthrough_df_output = pd.read_csv(BreakThrough_csv_files[0])\n",
    "\n",
    "# Read in the weekly game data and concat into one combined df\n",
    "BreakThrough_dfs = [pd.read_csv(file) for file in BreakThrough_csv_files]\n",
    "BreakThrough_df_output = pd.concat(BreakThrough_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Break_work = BreakThrough_df_output[[\"gameId\", \"playId\", \"frameId\", 'PassPlay',\n",
    "                                     \"club\", \"possessionTeam\", \"defensiveTeam\",\n",
    "                                       \"GotTheBall\", \"nflId\", \"displayName\", \"Covering\"]]\n",
    "\n",
    "player_name = players[[\"nflId\", \"position\"]]\n",
    "BreakThrough = Break_work.groupby([\"gameId\", \"playId\", \"frameId\"])[\"Covering\"].sum()\n",
    "\n",
    "BreakThrough = pd.merge(Break_work, BreakThrough, on = [\"gameId\", \"playId\", \"frameId\"])\n",
    "\n",
    "BreakThrough[\"BreakThrough\"] = np.where(BreakThrough[\"Covering_y\"] == 0, 1, 0)\n",
    "\n",
    "BreakThrough = BreakThrough[(BreakThrough[\"club\"] == BreakThrough[\"defensiveTeam\"])]\n",
    "\n",
    "# Group by 'nflId' and count the unique 'frameId' values in each group\n",
    "play_counts = BreakThrough.groupby('nflId')['playId'].nunique()\n",
    "\n",
    "# Create a new column 'TotalPlays' in the original DataFrame\n",
    "BreakThrough['TotalPlays'] = BreakThrough['nflId'].map(play_counts)\n",
    "BreakThrough = BreakThrough[BreakThrough[\"TotalPlays\"] >= 15]\n",
    "TotalPlays = BreakThrough[[\"nflId\",\"TotalPlays\"]].drop_duplicates()\n",
    "\n",
    "TeamNameJoin = BreakThrough[['club', \"nflId\", \"displayName\"]].drop_duplicates()\n",
    "\n",
    "\n",
    "Summarized_BreakThrough = pd.DataFrame()\n",
    "Summarized_BreakThrough[\"PassShielding\"] = BreakThrough[BreakThrough[\"PassPlay\"] == 1].groupby(\"nflId\")[\"Covering_x\"].mean()\n",
    "Summarized_BreakThrough[\"RushShielding\"] = BreakThrough[BreakThrough[\"PassPlay\"] == 0].groupby(\"nflId\")[\"Covering_x\"].mean()\n",
    "Summarized_BreakThrough[\"TotalShielding\"] = BreakThrough.groupby(\"nflId\")[\"Covering_x\"].mean()\n",
    "Summarized_BreakThrough = pd.merge(Summarized_BreakThrough, TotalPlays, on = \"nflId\")\n",
    "Summarized_BreakThrough = pd.merge(Summarized_BreakThrough, TeamNameJoin, on = \"nflId\")\n",
    "Summarized_BreakThrough = pd.merge(Summarized_BreakThrough, player_name, on = \"nflId\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summarized_BreakThrough.to_csv(\"insert path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team BreakThrough Perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BreakThrough_df_output = pd.read_csv(\"insert path\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Break_work = BreakThrough_df_output[[\"gameId\", \"playId\", \"frameId\", 'PassPlay', \"club\", \"possessionTeam\", \"defensiveTeam\", \"GotTheBall\", \"nflId\", \"displayName\", \"Covering\"]]\n",
    "player_name = players[[\"nflId\", \"position\"]]\n",
    "BreakThrough = Break_work.groupby([\"gameId\", \"playId\", \"frameId\"])[\"Covering\"].sum()\n",
    "\n",
    "BreakThrough = pd.merge(Break_work, BreakThrough, on = [\"gameId\", \"playId\", \"frameId\"])\n",
    "\n",
    "# Group by 'nflId' and count the unique 'frameId' values in each group\n",
    "play_counts = BreakThrough.groupby('nflId')['playId'].nunique()\n",
    "\n",
    "# Create a new column 'TotalPlays' in the original DataFrame\n",
    "BreakThrough['TotalPlays'] = BreakThrough['nflId'].map(play_counts)\n",
    "BreakThrough = BreakThrough[BreakThrough[\"TotalPlays\"] >= 15]\n",
    "\n",
    "BreakThrough[\"BreakThrough\"] = np.where(BreakThrough[\"Covering_y\"] == 0, 1, 0)\n",
    "\n",
    "\n",
    "DefensiveBreakThrough = pd.DataFrame()\n",
    "DefensiveBreakThrough[\"PassShielding\"] = BreakThrough[BreakThrough[\"PassPlay\"] == 1].groupby(\"defensiveTeam\")[\"Covering_x\"].mean()\n",
    "DefensiveBreakThrough[\"RushShielding\"] = BreakThrough[BreakThrough[\"PassPlay\"] == 0].groupby(\"defensiveTeam\")[\"Covering_x\"].mean()\n",
    "DefensiveBreakThrough[\"TotalShielding\"] = BreakThrough.groupby(\"defensiveTeam\")[\"Covering_x\"].mean()\n",
    "DefensiveBreakThrough = DefensiveBreakThrough.drop_duplicates()\n",
    "DefensiveBreakThrough.reset_index(inplace=True)\n",
    "\n",
    "DefensiveBreakThrough = DefensiveBreakThrough.sort_values(by=['TotalShielding'], ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DefensiveBreakThrough.to_csv(\"insert path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deviation from Ideal Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sethl\\AppData\\Local\\Temp\\ipykernel_5676\\913080507.py:1: DtypeWarning: Columns (61,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  BreakThrough_df_output = pd.read_csv(\"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Created_DF/AllGamesBreakthrough.csv\")\n"
     ]
    }
   ],
   "source": [
    "BreakThrough_df_output = pd.read_csv(\"insert path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(row):\n",
    "    Expected_x = (row[\"Ball_Max_x\"] + row['Ball_Min_x']) / 2\n",
    "    Expected_y = (row[\"Ball_Max_y\"] + row['Ball_Min_y']) / 2\n",
    "    delta_x = Expected_x - row['clean_x']\n",
    "    delta_y = Expected_y - row['clean_y']\n",
    "    angle_radians = math.atan2(delta_y, delta_x)\n",
    "    angle_radians = np.where(angle_radians < 0, angle_radians + 2 * math.pi, angle_radians) \n",
    "    angle_degrees = math.degrees(angle_radians)\n",
    "    return angle_degrees\n",
    "\n",
    "def Calculate_Deviation_From_Ideal(row):\n",
    "    Deviation = abs(row[\"clean_dir\"] - row[\"IdealAngle\"])**2\n",
    "    return Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Deviation = BreakThrough_df_output.copy()\n",
    "\n",
    "Deviation[\"IdealAngle\"] = Deviation.apply(calculate_angle, axis = 1)\n",
    "\n",
    "Deviation[\"Deviation\"] = Deviation.apply(Calculate_Deviation_From_Ideal, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeviationWork = Deviation[[\"gameId\", \"playId\", \"frameId\", 'PassPlay', \"club\", \"possessionTeam\", \"defensiveTeam\", \"GotTheBall\", \"nflId\",\\\n",
    "                            \"displayName\", 'distanceFromBall',\"clean_dir\", \"IdealAngle\",\n",
    "                              \"Deviation\"]]\n",
    "\n",
    "\n",
    "player_name = players[[\"nflId\", \"position\"]]\n",
    "\n",
    "DeviationWork = DeviationWork[(DeviationWork[\"club\"] == DeviationWork[\"defensiveTeam\"])]\n",
    "\n",
    "# Group by 'nflId' and count the unique 'frameId' values in each group\n",
    "play_counts = DeviationWork.groupby('nflId')['playId'].nunique()\n",
    "\n",
    "# Create a new column 'TotalPlays' in the original DataFrame\n",
    "DeviationWork['TotalPlays'] = DeviationWork['nflId'].map(play_counts)\n",
    "TotalPlays = DeviationWork[[\"nflId\",\"TotalPlays\"]].drop_duplicates()\n",
    "\n",
    "TeamNameJoin = DeviationWork[['club', \"nflId\", \"displayName\"]].drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "DeviationSummary = pd.DataFrame()\n",
    "DeviationSummary[\"PassMeanSquaredDeviation\"] = DeviationWork[DeviationWork[\"PassPlay\"] == 1].groupby(\"nflId\")[\"Deviation\"].mean()\n",
    "DeviationSummary[\"PassRootMeanSquaredDeviation\"] = np.sqrt(DeviationSummary[\"PassMeanSquaredDeviation\"])\n",
    "DeviationSummary[\"RushMeanSquaredDeviation\"] = DeviationWork[DeviationWork[\"PassPlay\"] == 0].groupby(\"nflId\")[\"Deviation\"].mean()\n",
    "DeviationSummary[\"RushRootMeanSquaredDeviation\"] = np.sqrt(DeviationSummary[\"RushMeanSquaredDeviation\"])\n",
    "DeviationSummary[\"TotalMeanSquaredDeviation\"] = DeviationWork.groupby(\"nflId\")[\"Deviation\"].mean()\n",
    "DeviationSummary[\"TotalRootMeanSquaredDeviation\"] = np.sqrt(DeviationSummary[\"TotalMeanSquaredDeviation\"])\n",
    "DeviationSummary = pd.merge(DeviationSummary, TotalPlays, on = \"nflId\")\n",
    "DeviationSummary = pd.merge(DeviationSummary, TeamNameJoin, on = \"nflId\")\n",
    "DeviationSummary = pd.merge(DeviationSummary, player_name, on = \"nflId\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Deviation.to_csv(\"insert path\", index=False)\n",
    "DeviationSummary.to_csv(\"insert path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Deviation = pd.read_csv(\"insert path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeviationWork = DeviationWork[DeviationWork[\"TotalPlays\"] >= 15]\n",
    "\n",
    "\n",
    "TeamDeviation = pd.DataFrame()\n",
    "TeamDeviation[\"PassMeanSquaredDeviation\"] = DeviationWork[DeviationWork[\"PassPlay\"] == 1].groupby(\"club\")[\"Deviation\"].mean()\n",
    "TeamDeviation[\"PassRootMeanSquaredDeviation\"] = np.sqrt(TeamDeviation[\"PassMeanSquaredDeviation\"])\n",
    "TeamDeviation[\"RushMeanSquaredDeviation\"] = DeviationWork[DeviationWork[\"PassPlay\"] == 0].groupby(\"club\")[\"Deviation\"].mean()\n",
    "TeamDeviation[\"RushRootMeanSquaredDeviation\"] = np.sqrt(TeamDeviation[\"RushMeanSquaredDeviation\"])\n",
    "TeamDeviation[\"TotalMeanSquaredDeviation\"] = DeviationWork.groupby(\"club\")[\"Deviation\"].mean()\n",
    "TeamDeviation[\"TotalRootMeanSquaredDeviation\"] = np.sqrt(TeamDeviation[\"TotalMeanSquaredDeviation\"])\n",
    "TeamDeviation = TeamDeviation.drop_duplicates()\n",
    "TeamDeviation.reset_index(inplace=True)\n",
    "\n",
    "TeamDeviation = TeamDeviation.sort_values(by=['TotalRootMeanSquaredDeviation'], ascending = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TeamDeviation.to_csv(\"insert path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PURSUIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BreakthroughSummarized = pd.read_csv(\"insert path\")\n",
    "ClosestSummary = pd.read_csv(\"insert path\")\n",
    "DeviationSummary = pd.read_csv(\"insert path\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AltPositionNames = {\n",
    "    \"DT\" : \"DT\",\n",
    "    \"NT\" : \"DT\",\n",
    "    \"MLB\" : \"LB\",\n",
    "    \"ILB\" : \"LB\",\n",
    "    \"DE\" : \"ED\",\n",
    "    \"OLB\" : \"ED\",\n",
    "    \"CB\" : \"CB\",\n",
    "    \"SS\" : \"S\",\n",
    "    \"FS\" : \"S\",\n",
    "    \"DB\" : \"LB\",\n",
    "}\n",
    "\n",
    "AltPositionGroups = {\n",
    "    \"DT\" : \"DL\",\n",
    "    \"NT\" : \"DL\",\n",
    "    \"MLB\" : \"LB\",\n",
    "    \"ILB\" : \"LB\",\n",
    "    \"DE\" : \"DL\",\n",
    "    \"OLB\" : \"DL\",\n",
    "    \"CB\" : \"DB\",\n",
    "    \"SS\" : \"DB\",\n",
    "    \"FS\" : \"DB\",\n",
    "    \"DB\" : \"LB\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_Defense = pd.merge(ClosestSummary, BreakthroughSummarized, on = [\"nflId\", \"displayName\", \"position\"])\n",
    "\n",
    "Full_Defense = pd.merge(Full_Defense, DeviationSummary, on = [\"nflId\", \"displayName\", \"position\"])\n",
    "\n",
    "Full_Defense = Full_Defense[Full_Defense[\"TotalPlays_x\"] >= 25]\n",
    "\n",
    "Full_Defense['Alt_Position'] = Full_Defense['position'].map(AltPositionGroups)\n",
    "\n",
    "\n",
    "Full_Defense = Full_Defense[[\"displayName\", \"nflId\", \"Alt_Position\", \"club_x\", \"TotalPlays_x\",\n",
    "                              'PassVoronoi', 'PassShielding', 'PassRootMeanSquaredDeviation',\n",
    "                             \n",
    "                              'RushVoronoi', 'RushShielding', 'RushRootMeanSquaredDeviation',\n",
    "                             \n",
    "                              'TotalVoronoi', 'TotalShielding', 'TotalRootMeanSquaredDeviation',\n",
    "                             ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_Defense.to_csv(\"insert path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DVoronoiTable = pd.read_csv(\"insert path\")\n",
    "DShieldTable = pd.read_csv(\"insert path\")\n",
    "DTackleTable = pd.read_csv(\"insert path\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DTeamTable = pd.merge(DVoronoiTable, DShieldTable, on = \"defensiveTeam\")\n",
    "DTeamTable = pd.merge(DTeamTable, DTackleTable, left_on = \"defensiveTeam\", right_on= \"club\")\n",
    "DTeamTable.drop(\"club\", axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTeamTable.to_csv(\"insert path\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S52",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
