{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, ArtistAnimation, Animation\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib\n",
    "\n",
    "# matplotlib.use('TkAgg')  # Use an appropriate backend (e.g., TkAgg)\n",
    "import matplotlib.patheffects as path_effects\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the relative path to the data directory\n",
    "data_folder_path = \"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Data\"\n",
    "non_games_data_folder_path = \"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Non_Games_Data\"\n",
    "\n",
    "# List all files in the data folder\n",
    "file_list = os.listdir(data_folder_path)\n",
    "file_list_non_games = os.listdir(non_games_data_folder_path)\n",
    "\n",
    "# Use glob to filter specific file types\n",
    "csv_files = glob.glob(os.path.join(data_folder_path, \"*.csv\"))\n",
    "csv_files_non_games = glob.glob(os.path.join(non_games_data_folder_path, \"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the weekly game data and concat into one combined df\n",
    "dfs = [pd.read_csv(file) for file in csv_files]\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Read in the supplementary data\n",
    "games = pd.read_csv(csv_files_non_games[0])\n",
    "nfl_colors = pd.read_csv(csv_files_non_games[1])\n",
    "pff_scouting_data = pd.read_csv(csv_files_non_games[2])\n",
    "players = pd.read_csv(csv_files_non_games[3])\n",
    "plays = pd.read_csv(csv_files_non_games[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the orientation of the plays\n",
    "clean_df = combined_df.copy()\n",
    "\"\"\"\n",
    "clean_df['x'] = clean_df.apply(lambda row: 120 - row['x'] if row['playDirection'] == \"left\" else row['x'], axis=1)\n",
    "clean_df['y'] = clean_df.apply(lambda row: 160 / 3 - row['y'] if row['playDirection'] == \"left\" else row['y'], axis=1)\n",
    "clean_df['dir'] = clean_df.apply(lambda row: row['dir'] + 180 if row['playDirection'] == \"left\" else row['dir'], axis=1)\n",
    "clean_df['dir'] = clean_df['dir'].apply(lambda val: val - 360 if val > 360 else val)\n",
    "clean_df['o'] = clean_df.apply(lambda row: row['o'] + 180 if row['playDirection'] == \"left\" else row['o'], axis=1)\n",
    "clean_df['o'] = clean_df['o'].apply(lambda val: val - 360 if val > 360 else val)\n",
    "\"\"\"\n",
    "\n",
    "# Merge nfl_colors and change the color of the football\n",
    "clean_df = pd.merge(clean_df, nfl_colors, left_on=\"team\", right_on=\"Code\", how=\"left\")\n",
    "clean_df[\"primary\"] = np.where(\n",
    "    clean_df[\"primary\"].isna(), \"#8b4513\", clean_df[\"primary\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutate 'df'\n",
    "filtered_df = clean_df.copy()\n",
    "\n",
    "filtered_df[\"is_start\"] = np.where(\n",
    "    filtered_df[\"event\"].isin([\"autoevent_ballsnap\", \"ball_snap\"]), 1, 0\n",
    ")\n",
    "filtered_df[\"is_end\"] = np.where(\n",
    "    filtered_df[\"event\"].isin(\n",
    "        [\n",
    "            \"fumble\",\n",
    "            \"handoff\",\n",
    "            \"lateral\",\n",
    "            \"autoevent_passforward\",\n",
    "            \"pass_forward\",\n",
    "            \"qb_sack\",\n",
    "            \"qb_strip_sack\",\n",
    "            \"run\",\n",
    "        ]\n",
    "    ),\n",
    "    1,\n",
    "    0,\n",
    ")\n",
    "\n",
    "# Group by and mutate 'df'\n",
    "grouped = filtered_df.groupby([\"gameId\", \"playId\"])\n",
    "filtered_df[\"any_start\"] = grouped[\"is_start\"].transform(\"any\")\n",
    "filtered_df[\"any_end\"] = grouped[\"is_end\"].transform(\"any\")\n",
    "\n",
    "# Filter and summarize 'df'\n",
    "intermediate_df = filtered_df[(filtered_df[\"any_start\"]) & (filtered_df[\"any_end\"])]\n",
    "\n",
    "\n",
    "# Define a function to calculate start_frame and end_frame\n",
    "def calculate_frames(group):\n",
    "    is_start_index = group[group[\"is_start\"] == 1].index[0]\n",
    "    start_frame = group.loc[is_start_index, \"frameId\"]\n",
    "\n",
    "    is_end_index = group[\n",
    "        (group[\"is_end\"] == 1) & (group[\"frameId\"] > start_frame)\n",
    "    ].index[0]\n",
    "    end_frame = group.loc[is_end_index, \"frameId\"]\n",
    "\n",
    "    return pd.Series({\"start_frame\": start_frame, \"end_frame\": end_frame})\n",
    "\n",
    "\n",
    "# Apply the function to each group and reset index\n",
    "frames_of_interest = (\n",
    "    intermediate_df.groupby([\"gameId\", \"playId\"]).apply(calculate_frames).reset_index()\n",
    ")\n",
    "\n",
    "# Mutate 'pff' for 'play_block_rush'\n",
    "pff_scouting_data[\"pff_role\"] = pff_scouting_data[\"pff_role\"].str.replace(\"Pass \", \"\")\n",
    "play_block_rush = pff_scouting_data[\n",
    "    pff_scouting_data[\"pff_role\"].isin([\"Block\", \"Rush\"])\n",
    "][[\"gameId\", \"playId\", \"nflId\", \"pff_role\", \"pff_positionLinedUp\"]]\n",
    "\n",
    "# Filter 'pff' for 'pff_network'\n",
    "pff_network = pff_scouting_data[\n",
    "    pff_scouting_data[\"pff_role\"].isin([\"Pass Block\", \"Pass Rush\", \"Pass\"])\n",
    "][[\"gameId\", \"playId\", \"nflId\", \"pff_role\", \"pff_positionLinedUp\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a WorkDF that is filtered down to just the frames of interest\n",
    "WorkDF = pd.merge(clean_df, frames_of_interest, on=[\"gameId\", \"playId\"], how=\"inner\")\n",
    "WorkDF = WorkDF[\n",
    "    (WorkDF[\"frameId\"] >= WorkDF[\"start_frame\"])\n",
    "    & (WorkDF[\"frameId\"] <= WorkDF[\"end_frame\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a feature on stunts, I would ideally want to differentiate between t-e stunts and e-t stunts\n",
    "\n",
    "Potentially also want to create a feature that is what gap they ended up attacking. That way we can cluster based on the ending gap of each DL player and that would create more distinct clusters for the predicted path algorithm to train on.\n",
    "Create gaps based on the ranges of y coordinates between the OL. I want to make it so that if you end up on the OL at the end of the play, it takes into account what orientation the OL is in. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sethl\\AppData\\Local\\Temp\\ipykernel_868\\3715502379.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Starting_Gaps[\"Cutoff_Point\"] = np.where(\n"
     ]
    }
   ],
   "source": [
    "# Filtering the WorkDF down to just the blockers\n",
    "StuntDF = pd.merge(\n",
    "    WorkDF, play_block_rush, on=[\"gameId\", \"playId\", \"nflId\"], how=\"inner\"\n",
    ")\n",
    "GapDF = StuntDF[\n",
    "    (StuntDF[\"pff_role\"] == \"Block\")\n",
    "    & (\n",
    "        StuntDF[\"pff_positionLinedUp\"].isin(\n",
    "            [\"LT\", \"LG\", \"C\", \"RG\", \"RT\", \"TE-L\", \"TE-R\"]\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "# Creating a wider dataset with the y positions for each OL position as a new column\n",
    "StuntWider = GapDF.pivot_table(\n",
    "    index=[\"gameId\", \"playId\", \"frameId\"], columns=\"pff_positionLinedUp\", values=\"y\"\n",
    ").reset_index()\n",
    "\n",
    "# Filling the missing data for TEs to help aid assignment later\n",
    "StuntWider[\"TE-L\"] = StuntWider[\"TE-L\"].fillna(100)\n",
    "StuntWider[\"TE-R\"] = StuntWider[\"TE-R\"].fillna(0)\n",
    "\n",
    "# Making a new dataframe that is just the pass rushers\n",
    "Starting_Gaps = StuntDF[(StuntDF[\"pff_role\"] == \"Rush\")]\n",
    "\n",
    "# Create Cutoff Point into the play\n",
    "Time_Cutoff = 20\n",
    "\n",
    "Starting_Gaps[\"Cutoff_Point\"] = np.where(\n",
    "    Starting_Gaps[\"end_frame\"] < Starting_Gaps[\"start_frame\"] + Time_Cutoff,\n",
    "    Starting_Gaps[\"end_frame\"],\n",
    "    Starting_Gaps[\"start_frame\"] + Time_Cutoff,\n",
    ")\n",
    "\n",
    "Starting_Gaps = Starting_Gaps[\n",
    "    (Starting_Gaps[\"frameId\"] >= Starting_Gaps[\"start_frame\"])\n",
    "    & (Starting_Gaps[\"frameId\"] <= Starting_Gaps[\"Cutoff_Point\"])\n",
    "]\n",
    "\n",
    "# Joining the OL Y positional data onto the Starting_Gaps df\n",
    "Starting_Gaps = pd.merge(Starting_Gaps, StuntWider, on=[\"gameId\", \"playId\", \"frameId\"])\n",
    "\n",
    "# Assigning the Gaps based on y position data\n",
    "conditions = [\n",
    "    Starting_Gaps[\"y\"] > Starting_Gaps[\"TE-L\"],\n",
    "    (Starting_Gaps[\"y\"] < Starting_Gaps[\"TE-L\"])\n",
    "    & (Starting_Gaps[\"y\"] > Starting_Gaps[\"LT\"]),\n",
    "    (Starting_Gaps[\"y\"] < Starting_Gaps[\"LT\"])\n",
    "    & (Starting_Gaps[\"y\"] > Starting_Gaps[\"LG\"]),\n",
    "    (Starting_Gaps[\"y\"] < Starting_Gaps[\"LG\"])\n",
    "    & (Starting_Gaps[\"y\"] > Starting_Gaps[\"C\"]),\n",
    "    (Starting_Gaps[\"y\"] < Starting_Gaps[\"C\"])\n",
    "    & (Starting_Gaps[\"y\"] > Starting_Gaps[\"RG\"]),\n",
    "    (Starting_Gaps[\"y\"] < Starting_Gaps[\"RG\"])\n",
    "    & (Starting_Gaps[\"y\"] > Starting_Gaps[\"RT\"]),\n",
    "    (Starting_Gaps[\"y\"] < Starting_Gaps[\"RT\"])\n",
    "    & (Starting_Gaps[\"y\"] > Starting_Gaps[\"TE-R\"]),\n",
    "    Starting_Gaps[\"y\"] < Starting_Gaps[\"TE-R\"],\n",
    "]\n",
    "choices = [\"L-D\", \"L-C\", \"L-B\", \"L-A\", \"R-A\", \"R-B\", \"R-C\", \"R-D\"]\n",
    "\n",
    "Starting_Gaps[\"Gap_Assignment\"] = np.select(conditions, choices, default=np.NAN)\n",
    "\n",
    "# Filling any NAN Gaps (which occur when the DL is directly on the OL Y value) with their previous Gap Assignment\n",
    "Starting_Gaps[\"Gap_Assignment\"] = Starting_Gaps.groupby([\"gameId\", \"playId\"])[\n",
    "    \"Gap_Assignment\"\n",
    "].fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Starting Gaps DF is setup so that for each defensive player, you have all of their positional data for the entire play, along with the OL Y positions for the entire play, and the Gap assignment for each frame as well.\n",
    "\n",
    "Depending on how the Clustering Algorithm wants the data in, it may be better to make new columns for starting and ending (x, y, gap) for each play. But given that I don't know what format the clustering algorithm needs, I will leave it in this format currently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter ffmpeg unavailable; using Pillow instead.\n"
     ]
    }
   ],
   "source": [
    "gameId = 2021090900\n",
    "playId = 137\n",
    "\n",
    "# Select specific columns from 'plays'\n",
    "selected_plays = plays[[\"gameId\", \"playId\", \"playDescription\"]]\n",
    "\n",
    "# Filter rows based on conditions\n",
    "filtered_plays = selected_plays[\n",
    "    (selected_plays[\"gameId\"] == gameId) & (selected_plays[\"playId\"] == playId)\n",
    "]\n",
    "\n",
    "# Perform left join with 'df'\n",
    "VizDF = filtered_plays.merge(clean_df, how=\"left\")\n",
    "\n",
    "VizDF[\"x_temp\"] = VizDF[\"y\"]\n",
    "VizDF[\"y_temp\"] = VizDF[\"x\"]\n",
    "VizDF[\"y\"] = VizDF[\"y_temp\"]\n",
    "VizDF[\"x\"] = VizDF[\"x_temp\"]\n",
    "VizDF = VizDF.drop([\"x_temp\", \"y_temp\"], axis=1)\n",
    "VizDF[\"jerseyNumber\"] = np.where(VizDF[\"jerseyNumber\"].isna(), 0, VizDF[\"jerseyNumber\"])\n",
    "VizDF[\"sinO\"] = np.sin(np.radians(VizDF[\"o\"]))\n",
    "VizDF[\"cosO\"] = np.cos(np.radians(VizDF[\"o\"]))\n",
    "\n",
    "ymin = 0\n",
    "ymax = 160 / 3\n",
    "hash_right = 38.35\n",
    "hash_left = 12\n",
    "hash_width = 3.3\n",
    "xmin = max(round(min(VizDF[\"y\"]) - 10, -1), 0)\n",
    "xmax = min(round(max(VizDF[\"y\"]) + 10, -1), 120)\n",
    "\n",
    "# Create a grid of coordinates (x, y)\n",
    "y_values = [0, 23.36667, 29.96667, ymax]\n",
    "x_values = list(range(10, 111))  # 10 to 110\n",
    "grid = pd.DataFrame({\"x\": x_values * len(y_values), \"y\": y_values * len(x_values)})\n",
    "\n",
    "# Filter rows based on conditions\n",
    "df_hash = grid[(grid[\"x\"] % 5 != 0) & (grid[\"x\"] < xmax) & (grid[\"x\"] > xmin)]\n",
    "# Create the base plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "\n",
    "for index, row in df_hash.iterrows():\n",
    "    if row[\"y\"] > 55 / 2:\n",
    "        ax.annotate(\n",
    "            \"|\", xy=(row[\"x\"] - 0.25, row[\"y\"]), va=\"top\", color=\"gray\", zorder=0\n",
    "        )\n",
    "    else:\n",
    "        ax.annotate(\n",
    "            \"|\", xy=(row[\"x\"] - 0.25, row[\"y\"]), va=\"bottom\", color=\"gray\", zorder=0\n",
    "        )\n",
    "\n",
    "# Add segment annotations\n",
    "for x in range(int(max(9, xmin)), int(min(xmax, 111)), 5):\n",
    "    ax.plot([x, x], [ymin, ymax], color=\"gray\", zorder=0)\n",
    "\n",
    "\n",
    "# Add text annotations on the sides\n",
    "y_labels = (\n",
    "    [\"   G\"]\n",
    "    + [str(val) for val in range(10, 51, 10)]\n",
    "    + [str(val) for val in reversed(range(10, 41, 10))]\n",
    "    + [\"G   \"]\n",
    ")\n",
    "\n",
    "yard_labels = pd.DataFrame(zip(range(10, 120, 10), y_labels), columns=[\"yard\", \"label\"])\n",
    "\n",
    "for x in range(int(max(10, xmin)), int(min(xmax, 120)), 10):\n",
    "    if (x != xmin) & (x != xmax):\n",
    "        label_top = yard_labels.loc[yard_labels[\"yard\"] == x, \"label\"].values[0]\n",
    "        label_bottom = yard_labels.loc[yard_labels[\"yard\"] == x, \"label\"].values[0]\n",
    "\n",
    "        ax.text(\n",
    "            x,\n",
    "            hash_left - 2,\n",
    "            label_top,\n",
    "            size=12,\n",
    "            color=\"gray\",\n",
    "            va=\"center\",\n",
    "            ha=\"center\",\n",
    "            zorder=0,\n",
    "        )\n",
    "        ax.text(\n",
    "            x,\n",
    "            ymax - hash_left + 2,\n",
    "            label_bottom,\n",
    "            size=12,\n",
    "            color=\"gray\",\n",
    "            va=\"center\",\n",
    "            ha=\"center\",\n",
    "            zorder=0,\n",
    "        )\n",
    "\n",
    "# Add field boundary lines\n",
    "ax.plot(\n",
    "    [xmin, xmin, xmax, xmax, xmin],\n",
    "    [ymin, ymax, ymax, ymin, ymin],\n",
    "    color=\"gray\",\n",
    "    zorder=0,\n",
    ")\n",
    "\n",
    "# Turn off both axes and tick labels\n",
    "ax.axis(\"off\")\n",
    "\n",
    "# Initialize the artists\n",
    "point_artists = []\n",
    "annotation_artists = []\n",
    "arrow_artists = []\n",
    "\n",
    "\n",
    "def init():\n",
    "    # Initialize the artists (empty at the beginning)\n",
    "    return arrow_artists + point_artists + annotation_artists\n",
    "\n",
    "\n",
    "def update(frame):\n",
    "    # Update the plot for each frame\n",
    "\n",
    "    # Clear the artists from the previous frame\n",
    "    for artist in arrow_artists + point_artists + annotation_artists:\n",
    "        artist.remove()\n",
    "    point_artists.clear()\n",
    "    annotation_artists.clear()\n",
    "    arrow_artists.clear()\n",
    "\n",
    "    # Get the rows for the current frame from the DataFrame\n",
    "    frame_rows = VizDF[VizDF[\"frameId\"] == frame + 5]\n",
    "\n",
    "    # Add/update dots for this frame\n",
    "    for index, row in frame_rows.iterrows():\n",
    "        x = row[\"y\"]\n",
    "        y = row[\"x\"]\n",
    "        color = row[\"primary\"]\n",
    "        jersey = row[\"jerseyNumber\"]\n",
    "        team = row[\"team\"]\n",
    "        sinO = row[\"sinO\"]\n",
    "        cosO = row[\"cosO\"]\n",
    "\n",
    "        if team == \"football\":\n",
    "            dot_artist1 = Line2D([x], [y], marker=\"d\", markersize=8, color=color)\n",
    "            ax.add_artist(dot_artist1)\n",
    "            point_artists.append(dot_artist1)\n",
    "\n",
    "        else:\n",
    "            dot_artist = Line2D(\n",
    "                [x], [y], marker=\"o\", markersize=20, color=color, zorder=2\n",
    "            )\n",
    "            ax.add_artist(dot_artist)\n",
    "            point_artists.append(dot_artist)\n",
    "\n",
    "            annotation_artist = ax.text(\n",
    "                x,\n",
    "                y,\n",
    "                str(round(int(jersey), 0)),\n",
    "                fontsize=10,\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                color=\"white\",\n",
    "                zorder=3,\n",
    "                path_effects=[\n",
    "                    path_effects.Stroke(linewidth=0.5, foreground=\"black\"),\n",
    "                    path_effects.Normal(),\n",
    "                ],\n",
    "            )\n",
    "            annotation_artists.append(annotation_artist)\n",
    "\n",
    "            arrow_artist = Line2D(\n",
    "                [x, x + sinO * 1],\n",
    "                [y, y + cosO * 1],\n",
    "                linestyle=\"--\",\n",
    "                dash_capstyle=\"round\",\n",
    "                linewidth=10,\n",
    "                zorder=1,\n",
    "                color=color,\n",
    "            )\n",
    "            ax.add_artist(arrow_artist)\n",
    "            arrow_artists.append(arrow_artist)\n",
    "\n",
    "    return arrow_artists + annotation_artists + point_artists\n",
    "\n",
    "\n",
    "ex_play_lengthVIZ = VizDF[\"frameId\"].nunique()\n",
    "\n",
    "# Create the animation\n",
    "animation = FuncAnimation(\n",
    "    fig,\n",
    "    update,\n",
    "    frames=range(ex_play_lengthVIZ),\n",
    "    init_func=init,\n",
    "    blit=True,\n",
    "    interval=100,\n",
    ")\n",
    "\n",
    "animation.save(\"Sample Validation Viz.gif\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S52",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
