{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the relative path to the data directory\n",
    "data_folder_path = \"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Data\"\n",
    "non_games_data_folder_path = \"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Non_Games_Data\"\n",
    "\n",
    "# List all files in the data folder\n",
    "file_list = os.listdir(data_folder_path)\n",
    "file_list_non_games = os.listdir(non_games_data_folder_path)\n",
    "\n",
    "# Use glob to filter specific file types\n",
    "csv_files = glob.glob(os.path.join(data_folder_path, \"*.csv\"))\n",
    "csv_files_non_games = glob.glob(os.path.join(non_games_data_folder_path, \"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the weekly game data and concat into one combined df\n",
    "dfs = [pd.read_csv(file) for file in csv_files]\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Read in the supplementary data\n",
    "games = pd.read_csv(csv_files_non_games[0])\n",
    "nfl_colors = pd.read_csv(csv_files_non_games[1])\n",
    "players = pd.read_csv(csv_files_non_games[2])\n",
    "plays = pd.read_csv(csv_files_non_games[3])\n",
    "tackles = pd.read_csv(csv_files_non_games[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.read_csv(\"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Created_DF/clean_df.csv\")\n",
    "\n",
    "#Full Clean\n",
    "#clean_df = pd.read_csv(\"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Created_DF/full_clean_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the orientation of the plays\n",
    "clean_df = combined_df.copy()\n",
    "\n",
    "clean_df['clean_x'] = clean_df.apply(lambda row: 120 - row['x'] if row['playDirection'] == \"left\" else row['x'], axis=1)\n",
    "clean_df['clean_y'] = clean_df.apply(lambda row: 160 / 3 - row['y'] if row['playDirection'] == \"left\" else row['y'], axis=1)\n",
    "clean_df['clean_dir'] = clean_df.apply(lambda row: row['dir'] + 180 if row['playDirection'] == \"left\" else row['dir'], axis=1)\n",
    "clean_df['clean_dir'] = clean_df['clean_dir'].apply(lambda val: val - 360 if val > 360 else val)\n",
    "clean_df['clean_o'] = clean_df.apply(lambda row: row['o'] + 180 if row['playDirection'] == \"left\" else row['o'], axis=1)\n",
    "clean_df['clean_o'] = clean_df['clean_o'].apply(lambda val: val - 360 if val > 360 else val)\n",
    "\n",
    "\n",
    "# Merge nfl_colors and change the color of the football\n",
    "clean_df = pd.merge(clean_df, nfl_colors, left_on=\"club\", right_on=\"Code\", how=\"left\")\n",
    "clean_df[\"primary\"] = np.where(\n",
    "    clean_df[\"primary\"].isna(), \"#8b4513\", clean_df[\"primary\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv(\"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Created_DF/full_clean_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_df[\"event\"].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sethl\\AppData\\Local\\Temp\\ipykernel_21120\\455596652.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  GotTheBall[\"GotTheBall\"] = 1\n"
     ]
    }
   ],
   "source": [
    "# Mutate 'df'\n",
    "filtered_df = clean_df.copy()\n",
    "\n",
    "filtered_df[\"is_start\"] = np.where(\n",
    "    filtered_df[\"event\"].isin(\n",
    "        [\n",
    "            \"autoevent_ballsnap\",\n",
    "              \"ball_snap\",\n",
    "                \"pass_arrived\",\n",
    "                  \"pass_outcome_caught\",\n",
    "                  \"pass_outcome_touchdown\",\n",
    "                    \"run\",\n",
    "                      \"snap_direct\",\n",
    "                      \"handoff\"\n",
    "    ]), 1, 0\n",
    ")\n",
    "filtered_df[\"is_end\"] = np.where(\n",
    "    filtered_df[\"event\"].isin(\n",
    "        [\n",
    "            \"tackle\",\n",
    "            \"touchdown\",\n",
    "            \"out_of_bounds\",\n",
    "            \"fumble\",\n",
    "            \"lateral\",\n",
    "            \"qb_sack\",\n",
    "            \"autoevent_passinterrupted\",\n",
    "            \"safety\",\n",
    "            \"autoevent_passinterrupted\"\n",
    "        ]\n",
    "    ),\n",
    "    1,\n",
    "    0,\n",
    ")\n",
    "# Group by and mutate 'df'\n",
    "grouped = filtered_df.groupby([\"gameId\", \"playId\"])\n",
    "filtered_df[\"any_start\"] = grouped[\"is_start\"].transform(\"any\")\n",
    "filtered_df[\"any_end\"] = grouped[\"is_end\"].transform(\"any\")\n",
    "\n",
    "# Filter and summarize 'df'\n",
    "intermediate_df = filtered_df[(filtered_df[\"any_start\"]) & (filtered_df[\"any_end\"])]\n",
    "\n",
    "\n",
    "# Define a function to calculate start_frame and end_frame\n",
    "def calculate_frames(group):\n",
    "    start_indices = group[group[\"is_start\"] == 1].index\n",
    "    if len(start_indices) == 0:\n",
    "        return pd.Series({\"start_frame\": None, \"end_frame\": None})\n",
    "\n",
    "    start_frame = group.loc[start_indices[0], \"frameId\"]\n",
    "\n",
    "    end_indices = group[(group[\"is_end\"] == 1) & (group[\"frameId\"] > start_frame)].index\n",
    "    if len(end_indices) == 0:\n",
    "        last_row_index = group.index[-1]  # Get the index of the last row in the group\n",
    "        end_frame = group.loc[last_row_index, \"frameId\"]\n",
    "    else:\n",
    "        end_frame = group.loc[end_indices[0], \"frameId\"]\n",
    "\n",
    "    return pd.Series({\"start_frame\": start_frame, \"end_frame\": end_frame})\n",
    "\n",
    "\n",
    "# Apply the function to each group and reset index\n",
    "frames_of_interest = (\n",
    "    intermediate_df.groupby([\"gameId\", \"playId\"]).apply(calculate_frames).reset_index()\n",
    ")\n",
    "\n",
    "GotTheBall = plays[[\"gameId\", \"playId\", \"ballCarrierId\"]]\n",
    "GotTheBall[\"GotTheBall\"] = 1\n",
    "\n",
    "\n",
    "filtered_df[\"Pass\"] = np.where(\n",
    "    filtered_df[\"event\"].isin(\n",
    "        [\n",
    "             \"pass_arrived\",\n",
    "                  \"pass_outcome_caught\",\n",
    "                  \"pass_outcome_touchdown\"\n",
    "    ]), 1, 0\n",
    ")\n",
    "\n",
    "filtered_df['PassPlay'] = filtered_df.groupby(['gameId', 'playId'])['Pass'].transform('max')\n",
    "\n",
    "PassPlay = filtered_df[['gameId', 'playId', 'PassPlay']].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a WorkDF that is filtered down to just the frames of interest\n",
    "WorkDF = pd.merge(clean_df, frames_of_interest, on=[\"gameId\", \"playId\"], how=\"inner\")\n",
    "WorkDF = WorkDF[\n",
    "    (WorkDF[\"frameId\"] >= WorkDF[\"start_frame\"])\n",
    "    & (WorkDF[\"frameId\"] <= WorkDF[\"end_frame\"])\n",
    "]\n",
    "\n",
    "\n",
    "WorkDF = pd.merge(WorkDF, GotTheBall,\n",
    "                   left_on = [\"gameId\", \"playId\", \"nflId\"],\n",
    "                   right_on=[\"gameId\", \"playId\", \"ballCarrierId\"],\n",
    "                   how = \"left\")\n",
    "\n",
    "\n",
    "WorkDF = pd.merge(WorkDF, PassPlay,\n",
    "                   on = [\"gameId\", \"playId\"],\n",
    "                   how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WorkDF.to_csv(\"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Created_DF/small_WorkDF.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a feature on stunts, I would ideally want to differentiate between t-e stunts and e-t stunts\n",
    "\n",
    "Potentially also want to create a feature that is what gap they ended up attacking. That way we can cluster based on the ending gap of each DL player and that would create more distinct clusters for the predicted path algorithm to train on.\n",
    "Create gaps based on the ranges of y coordinates between the OL. I want to make it so that if you end up on the OL at the end of the play, it takes into account what orientation the OL is in. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the WorkDF down to just the blockers\n",
    "StuntDF = pd.merge(\n",
    "    WorkDF, play_block_rush, on=[\"gameId\", \"playId\", \"nflId\"], how=\"inner\"\n",
    ")\n",
    "\n",
    "\n",
    "# Making Center Adjusted Coordinates for every player\n",
    "StuntDF = StuntDF.sort_values(by=[\"gameId\", \"playId\", \"frameId\", \"pff_positionLinedUp\"])\n",
    "first_frame = StuntDF[StuntDF[\"pff_positionLinedUp\"] == \"C\"].groupby([\"gameId\", \"playId\"]).transform(\"first\")\n",
    "StuntDF[\"C_x\"] = first_frame[\"clean_x\"]\n",
    "StuntDF[\"C_y\"] = first_frame[\"clean_y\"]\n",
    "StuntDF[\"C_x\"] = StuntDF.groupby([\"gameId\", \"playId\"])[\"C_x\"].fillna(method=\"ffill\")\n",
    "StuntDF[\"C_y\"] = StuntDF.groupby([\"gameId\", \"playId\"])[\"C_y\"].fillna(method=\"ffill\")\n",
    "StuntDF[\"C_adjusted_x\"] = StuntDF[\"clean_x\"] - StuntDF[\"C_x\"]\n",
    "StuntDF[\"C_adjusted_y\"] = StuntDF[\"clean_y\"] - StuntDF[\"C_y\"]\n",
    "\n",
    "\n",
    "GapDF = StuntDF[\n",
    "    (StuntDF[\"pff_role\"] == \"Block\")\n",
    "    & (\n",
    "        StuntDF[\"pff_positionLinedUp\"].isin(\n",
    "            [\"LT\", \"LG\", \"C\", \"RG\", \"RT\", \"TE-L\", \"TE-R\"]\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "# Creating a wider dataset with the y positions for each OL position as a new column\n",
    "StuntWider = GapDF.pivot_table(\n",
    "    index=[\"gameId\", \"playId\", \"frameId\"], columns=\"pff_positionLinedUp\", values=\"C_adjusted_y\"\n",
    ").reset_index()\n",
    "\n",
    "# Filling the missing data for TEs to help aid assignment later\n",
    "StuntWider[\"TE-L\"] = StuntWider[\"TE-L\"].fillna(100)\n",
    "StuntWider[\"TE-R\"] = StuntWider[\"TE-R\"].fillna(0)\n",
    "\n",
    "# Making a new dataframe that is just the pass rushers\n",
    "Starting_Gaps = StuntDF[(StuntDF[\"pff_role\"] == \"Rush\")]\n",
    "\n",
    "# Create Cutoff Point into the play\n",
    "Time_Cutoff = 20\n",
    "\n",
    "Starting_Gaps[\"Cutoff_Point\"] = np.where(\n",
    "    Starting_Gaps[\"end_frame\"] < Starting_Gaps[\"start_frame\"] + Time_Cutoff,\n",
    "    Starting_Gaps[\"end_frame\"],\n",
    "    Starting_Gaps[\"start_frame\"] + Time_Cutoff,\n",
    ")\n",
    "\n",
    "Starting_Gaps = Starting_Gaps[\n",
    "    (Starting_Gaps[\"frameId\"] >= Starting_Gaps[\"start_frame\"])\n",
    "    & (Starting_Gaps[\"frameId\"] <= Starting_Gaps[\"Cutoff_Point\"])\n",
    "]\n",
    "\n",
    "# Joining the OL Y positional data onto the Starting_Gaps df\n",
    "Starting_Gaps = pd.merge(Starting_Gaps, StuntWider, on=[\"gameId\", \"playId\", \"frameId\"])\n",
    "\n",
    "# Assigning the Gaps based on y position data\n",
    "conditions = [\n",
    "    Starting_Gaps[\"C_adjusted_y\"] > Starting_Gaps[\"TE-L\"],\n",
    "    (Starting_Gaps[\"C_adjusted_y\"] < Starting_Gaps[\"TE-L\"])\n",
    "    & (Starting_Gaps[\"C_adjusted_y\"] > Starting_Gaps[\"LT\"]),\n",
    "    (Starting_Gaps[\"C_adjusted_y\"] < Starting_Gaps[\"LT\"])\n",
    "    & (Starting_Gaps[\"C_adjusted_y\"] > Starting_Gaps[\"LG\"]),\n",
    "    (Starting_Gaps[\"C_adjusted_y\"] < Starting_Gaps[\"LG\"])\n",
    "    & (Starting_Gaps[\"C_adjusted_y\"] > Starting_Gaps[\"C\"]),\n",
    "    (Starting_Gaps[\"C_adjusted_y\"] < Starting_Gaps[\"C\"])\n",
    "    & (Starting_Gaps[\"C_adjusted_y\"] > Starting_Gaps[\"RG\"]),\n",
    "    (Starting_Gaps[\"C_adjusted_y\"] < Starting_Gaps[\"RG\"])\n",
    "    & (Starting_Gaps[\"C_adjusted_y\"] > Starting_Gaps[\"RT\"]),\n",
    "    (Starting_Gaps[\"C_adjusted_y\"] < Starting_Gaps[\"RT\"])\n",
    "    & (Starting_Gaps[\"C_adjusted_y\"] > Starting_Gaps[\"TE-R\"]),\n",
    "    Starting_Gaps[\"C_adjusted_y\"] < Starting_Gaps[\"TE-R\"],\n",
    "]\n",
    "choices = [\"L-D\", \"L-C\", \"L-B\", \"L-A\", \"R-A\", \"R-B\", \"R-C\", \"R-D\"]\n",
    "\n",
    "Starting_Gaps[\"Gap_Assignment\"] = np.select(conditions, choices, default=np.NAN)\n",
    "\n",
    "# Filling any NAN Gaps (which occur when the DL is directly on the OL Y value) with their previous Gap Assignment\n",
    "Starting_Gaps[\"Gap_Assignment\"] = Starting_Gaps.groupby([\"gameId\", \"playId\"])[\n",
    "    \"Gap_Assignment\"\n",
    "].fillna(method=\"ffill\")\n",
    "\n",
    "\n",
    "Start_Gap = Starting_Gaps[Starting_Gaps[\"frameId\"] == Starting_Gaps[\"start_frame\"]].groupby([\"gameId\", \"playId\", \"nflId\"])[[\"gameId\", \"playId\", \"nflId\",\"Gap_Assignment\"]].transform('first')\n",
    "End_Gap = Starting_Gaps[Starting_Gaps[\"frameId\"] == Starting_Gaps[\"end_frame\"]].groupby([\"gameId\", \"playId\", \"nflId\"])[[\"gameId\", \"playId\", \"nflId\",\"Gap_Assignment\"]].transform('first')\n",
    "\n",
    "Starting_Gaps = pd.merge(Starting_Gaps, Start_Gap, on=[\"gameId\", \"playId\", \"nflId\"])\n",
    "Starting_Gaps = pd.merge(Starting_Gaps, End_Gap, on=[\"gameId\", \"playId\", \"nflId\"])\n",
    "\n",
    "Starting_Gaps['RushPath'] = Starting_Gaps['Gap_Assignment_y'] + '-' + Starting_Gaps['Gap_Assignment'].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a One Hot Encoding for the Rush Paths types on a given play\n",
    "RushPaths = Starting_Gaps.copy()\n",
    "\n",
    "RushPaths = RushPaths.pivot_table(\n",
    "    index=[\"gameId\", \"playId\"], columns = \"RushPath\", values=\"frameId\"\n",
    ").reset_index()\n",
    "\n",
    "exclude_columns = [\"gameId\", \"playId\"]\n",
    "\n",
    "RushPaths.loc[:, ~RushPaths.columns.isin(exclude_columns)] = RushPaths.loc[:, ~RushPaths.columns.isin(exclude_columns)].notna().replace(True, 1)\n",
    "RushPaths = RushPaths.replace(False, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Number of Rushers on a play\n",
    "Rushers = StuntDF.copy()\n",
    "\n",
    "Rushers = Rushers.groupby(['gameId', 'playId', 'nflId']) \\\n",
    "                  .head(1) \\\n",
    "                  .assign(Rushers=lambda x: x.groupby(['gameId', 'playId'])['gameId'].transform('count'))\n",
    "\n",
    "Rushers = Rushers[[\"gameId\", \"playId\", \"Rushers\"]].drop_duplicates()\n",
    "\n",
    "#Creating Number of Blockers on a play\n",
    "Blockers = StuntDF.copy()\n",
    "\n",
    "Blockers = Blockers[Blockers[\"pff_role\"] == \"Block\"].groupby(['gameId', 'playId', 'nflId']) \\\n",
    "                  .head(1) \\\n",
    "                  .assign(Blockers=lambda x: x.groupby(['gameId', 'playId'])['gameId'].transform('count'))\n",
    "\n",
    "Blockers = Blockers[[\"gameId\", \"playId\", \"Blockers\"]].drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a One-Hot Encoding for the positions on a given play\n",
    "Positions = StuntDF.copy()\n",
    "\n",
    "Positions = Positions.pivot_table(\n",
    "    index=[\"gameId\", \"playId\"], columns = \"pff_positionLinedUp\", values=\"frameId\"\n",
    ").reset_index()\n",
    "\n",
    "exclude_columns = [\"gameId\", \"playId\"]\n",
    "\n",
    "Positions.loc[:, ~Positions.columns.isin(exclude_columns)] = Positions.loc[:, ~Positions.columns.isin(exclude_columns)].notna().replace(True, 1)\n",
    "Positions = Positions.replace(False, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a One Hot Encoding for the Block types on a given play\n",
    "BlockTypes = StuntDF.copy()\n",
    "\n",
    "BlockTypes = BlockTypes.pivot_table(\n",
    "    index=[\"gameId\", \"playId\"], columns = \"pff_blockType\", values=\"frameId\"\n",
    ").reset_index()\n",
    "\n",
    "exclude_columns = [\"gameId\", \"playId\"]\n",
    "\n",
    "BlockTypes.loc[:, ~BlockTypes.columns.isin(exclude_columns)] = BlockTypes.loc[:, ~BlockTypes.columns.isin(exclude_columns)].notna().replace(True, 1)\n",
    "BlockTypes = BlockTypes.replace(False, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "man_zone_encoding = pd.get_dummies(man_zone, columns=['pff_passCoverage', 'pff_passCoverageType'])\n",
    "\n",
    "play_encoding = pd.get_dummies(play_info, columns=[\"offenseFormation\", \"personnelO\", \"personnelD\", \"defendersInBox\", \"dropBackType\", \"pff_playAction\"])\n",
    "\n",
    "Center_LOC = pff_scouting_data[[\"gameId\", \"playId\", \"nflId\", \"pff_positionLinedUp\"]]\n",
    "\n",
    "# Filtering the WorkDF down to just the blockers\n",
    "C_AdjustedDF = pd.merge(\n",
    "    WorkDF, Center_LOC, on=[\"gameId\", \"playId\", \"nflId\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Making Center Adjusted Coordinates for every player\n",
    "C_AdjustedDF = C_AdjustedDF.sort_values(by=[\"gameId\", \"playId\", \"frameId\", \"pff_positionLinedUp\"])\n",
    "first_frame = C_AdjustedDF[C_AdjustedDF[\"pff_positionLinedUp\"] == \"C\"].groupby([\"gameId\", \"playId\"]).transform(\"first\")\n",
    "C_AdjustedDF[\"C_x\"] = first_frame[\"clean_x\"]\n",
    "C_AdjustedDF[\"C_y\"] = first_frame[\"clean_y\"]\n",
    "C_AdjustedDF[\"C_x\"] = C_AdjustedDF.groupby([\"gameId\", \"playId\"])[\"C_x\"].fillna(method=\"ffill\")\n",
    "C_AdjustedDF[\"C_y\"] = C_AdjustedDF.groupby([\"gameId\", \"playId\"])[\"C_y\"].fillna(method=\"ffill\")\n",
    "C_AdjustedDF[\"C_adjusted_x\"] = C_AdjustedDF[\"clean_x\"] - C_AdjustedDF[\"C_x\"]\n",
    "C_AdjustedDF[\"C_adjusted_y\"] = C_AdjustedDF[\"clean_y\"] - C_AdjustedDF[\"C_y\"]\n",
    "\n",
    "C_AdjustedDF = C_AdjustedDF[[\"gameId\", \"playId\", \"nflId\", \"frameId\", \"C_adjusted_x\", \"C_adjusted_y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_AdjustedDF.to_csv(\"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Created_DF/C_AdjustedDF.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RoutesDf = pd.merge(\n",
    "    WorkDF, play_route_coverage, on=[\"gameId\", \"playId\", \"nflId\"], how=\"inner\"\n",
    ")\n",
    "\n",
    "ClusterDF = RoutesDf[[\"gameId\", \"playId\"]].drop_duplicates()\n",
    "\n",
    "ClusterDF = pd.merge(ClusterDF, man_zone_encoding, on=[\"gameId\", \"playId\"])\n",
    "ClusterDF = pd.merge(ClusterDF, play_encoding, on=[\"gameId\", \"playId\"])\n",
    "ClusterDF = pd.merge(ClusterDF, Rushers, on=[\"gameId\", \"playId\"])\n",
    "ClusterDF = pd.merge(ClusterDF, Blockers, on=[\"gameId\", \"playId\"])\n",
    "ClusterDF = pd.merge(ClusterDF, Positions, on=[\"gameId\", \"playId\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=100)  # Replace 3 with your chosen K value\n",
    "kmeans.fit(ClusterDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClusterDF['Cluster'] = kmeans.labels_\n",
    "\n",
    "FinalClusterJoin = ClusterDF[[\"gameId\", \"playId\", \"Cluster\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClusterDF.to_csv(\"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Created_DF/ClusterDF.csv\", index=False)\n",
    "RoutesDf.to_csv(\"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Created_DF/RoutesDf.csv\", index=False)\n",
    "\n",
    "#Starting_Gaps.to_csv(\"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Created_DF/Starting_Gaps.csv\", index=False)\n",
    "StuntDF.to_csv(\"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Created_DF/StuntDF.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S52",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
