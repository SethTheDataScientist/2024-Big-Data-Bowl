{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the relative path to the data directory\n",
    "data_folder_path = \"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Data\"\n",
    "non_games_data_folder_path = \"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Non_Games_Data\"\n",
    "\n",
    "# List all files in the data folder\n",
    "file_list = os.listdir(data_folder_path)\n",
    "file_list_non_games = os.listdir(non_games_data_folder_path)\n",
    "\n",
    "# Use glob to filter specific file types\n",
    "csv_files = glob.glob(os.path.join(data_folder_path, \"*.csv\"))\n",
    "csv_files_non_games = glob.glob(os.path.join(non_games_data_folder_path, \"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the weekly game data and concat into one combined df\n",
    "dfs = [pd.read_csv(file) for file in csv_files]\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Read in the supplementary data\n",
    "games = pd.read_csv(csv_files_non_games[0])\n",
    "nfl_colors = pd.read_csv(csv_files_non_games[1])\n",
    "pff_scouting_data = pd.read_csv(csv_files_non_games[2])\n",
    "players = pd.read_csv(csv_files_non_games[3])\n",
    "plays = pd.read_csv(csv_files_non_games[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_df = pd.read_csv(\"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Created_DF/clean_df.csv\")\n",
    "\n",
    "#Full Clean\n",
    "clean_df = pd.read_csv(\"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Created_DF/full_clean_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the orientation of the plays\n",
    "clean_df = combined_df.copy()\n",
    "\n",
    "clean_df['clean_x'] = clean_df.apply(lambda row: 120 - row['x'] if row['playDirection'] == \"left\" else row['x'], axis=1)\n",
    "clean_df['clean_y'] = clean_df.apply(lambda row: 160 / 3 - row['y'] if row['playDirection'] == \"left\" else row['y'], axis=1)\n",
    "clean_df['clean_dir'] = clean_df.apply(lambda row: row['dir'] + 180 if row['playDirection'] == \"left\" else row['dir'], axis=1)\n",
    "clean_df['clean_dir'] = clean_df['clean_dir'].apply(lambda val: val - 360 if val > 360 else val)\n",
    "clean_df['clean_o'] = clean_df.apply(lambda row: row['o'] + 180 if row['playDirection'] == \"left\" else row['o'], axis=1)\n",
    "clean_df['clean_o'] = clean_df['clean_o'].apply(lambda val: val - 360 if val > 360 else val)\n",
    "\n",
    "\n",
    "# Merge nfl_colors and change the color of the football\n",
    "clean_df = pd.merge(clean_df, nfl_colors, left_on=\"team\", right_on=\"Code\", how=\"left\")\n",
    "clean_df[\"primary\"] = np.where(\n",
    "    clean_df[\"primary\"].isna(), \"#8b4513\", clean_df[\"primary\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv(\"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Created_DF/full_clean_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutate 'df'\n",
    "filtered_df = clean_df.copy()\n",
    "\n",
    "filtered_df[\"is_start\"] = np.where(\n",
    "    filtered_df[\"event\"].isin([\"autoevent_ballsnap\", \"ball_snap\"]), 1, 0\n",
    ")\n",
    "filtered_df[\"is_end\"] = np.where(\n",
    "    filtered_df[\"event\"].isin(\n",
    "        [\n",
    "            \"fumble\",\n",
    "            \"handoff\",\n",
    "            \"lateral\",\n",
    "            \"autoevent_passforward\",\n",
    "            \"pass_forward\",\n",
    "            \"pass_outcome_caught\",\n",
    "            \"pass_outcome_incomplete\",\n",
    "            \"qb_sack\",\n",
    "            \"qb_strip_sack\",\n",
    "            \"run\",\n",
    "        ]\n",
    "    ),\n",
    "    1,\n",
    "    0,\n",
    ")\n",
    "\n",
    "# Group by and mutate 'df'\n",
    "grouped = filtered_df.groupby([\"gameId\", \"playId\"])\n",
    "filtered_df[\"any_start\"] = grouped[\"is_start\"].transform(\"any\")\n",
    "filtered_df[\"any_end\"] = grouped[\"is_end\"].transform(\"any\")\n",
    "\n",
    "# Filter and summarize 'df'\n",
    "intermediate_df = filtered_df[(filtered_df[\"any_start\"]) & (filtered_df[\"any_end\"])]\n",
    "\n",
    "\n",
    "# Define a function to calculate start_frame and end_frame\n",
    "def calculate_frames(group):\n",
    "    is_start_index = group[group[\"is_start\"] == 1].index[0]\n",
    "    start_frame = group.loc[is_start_index, \"frameId\"]\n",
    "\n",
    "    is_end_index = group[\n",
    "        (group[\"is_end\"] == 1) & (group[\"frameId\"] > start_frame)\n",
    "    ].index[0]\n",
    "    end_frame = group.loc[is_end_index, \"frameId\"]\n",
    "\n",
    "    return pd.Series({\"start_frame\": start_frame, \"end_frame\": end_frame})\n",
    "\n",
    "\n",
    "# Apply the function to each group and reset index\n",
    "frames_of_interest = (\n",
    "    intermediate_df.groupby([\"gameId\", \"playId\"]).apply(calculate_frames).reset_index()\n",
    ")\n",
    "\n",
    "# Mutate 'pff' for 'play_block_rush'\n",
    "pff_scouting_data[\"pff_role\"] = pff_scouting_data[\"pff_role\"].str.replace(\"Pass \", \"\")\n",
    "play_block_rush = pff_scouting_data[\n",
    "    pff_scouting_data[\"pff_role\"].isin([\"Block\", \"Rush\"])\n",
    "][[\"gameId\", \"playId\", \"nflId\", \"pff_role\", \"pff_positionLinedUp\", \"pff_blockType\"]]\n",
    "\n",
    "\n",
    "play_route_coverage = pff_scouting_data[\n",
    "    pff_scouting_data[\"pff_role\"].isin([\"Route\", \"Coverage\"])\n",
    "][[\"gameId\", \"playId\", \"nflId\", \"pff_role\", \"pff_positionLinedUp\", \"pff_blockType\"]]\n",
    "\n",
    "\n",
    "# Filter 'pff' for 'pff_network'\n",
    "pff_network = pff_scouting_data[\n",
    "    pff_scouting_data[\"pff_role\"].isin([\"Pass Block\", \"Pass Rush\", \"Pass\"])\n",
    "][[\"gameId\", \"playId\", \"nflId\", \"pff_role\", \"pff_positionLinedUp\"]]\n",
    "\n",
    "man_zone = plays[[\"gameId\", \"playId\", \"pff_passCoverage\", \"pff_passCoverageType\"]]\n",
    "\n",
    "play_info = plays[[\"gameId\", \"playId\", \"offenseFormation\", \"personnelO\", \"personnelD\", \"defendersInBox\", \"dropBackType\", \"pff_playAction\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a WorkDF that is filtered down to just the frames of interest\n",
    "WorkDF = pd.merge(clean_df, frames_of_interest, on=[\"gameId\", \"playId\"], how=\"inner\")\n",
    "WorkDF = WorkDF[\n",
    "    (WorkDF[\"frameId\"] >= WorkDF[\"start_frame\"])\n",
    "    & (WorkDF[\"frameId\"] <= WorkDF[\"end_frame\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a feature on stunts, I would ideally want to differentiate between t-e stunts and e-t stunts\n",
    "\n",
    "Potentially also want to create a feature that is what gap they ended up attacking. That way we can cluster based on the ending gap of each DL player and that would create more distinct clusters for the predicted path algorithm to train on.\n",
    "Create gaps based on the ranges of y coordinates between the OL. I want to make it so that if you end up on the OL at the end of the play, it takes into account what orientation the OL is in. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sethl\\AppData\\Local\\Temp\\ipykernel_9208\\1329652044.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Starting_Gaps[\"Cutoff_Point\"] = np.where(\n"
     ]
    }
   ],
   "source": [
    "# Filtering the WorkDF down to just the blockers\n",
    "StuntDF = pd.merge(\n",
    "    WorkDF, play_block_rush, on=[\"gameId\", \"playId\", \"nflId\"], how=\"inner\"\n",
    ")\n",
    "\n",
    "\n",
    "# Making Center Adjusted Coordinates for every player\n",
    "StuntDF = StuntDF.sort_values(by=[\"gameId\", \"playId\", \"frameId\", \"pff_positionLinedUp\"])\n",
    "first_frame = StuntDF[StuntDF[\"pff_positionLinedUp\"] == \"C\"].groupby([\"gameId\", \"playId\"]).transform(\"first\")\n",
    "StuntDF[\"C_x\"] = first_frame[\"clean_x\"]\n",
    "StuntDF[\"C_y\"] = first_frame[\"clean_y\"]\n",
    "StuntDF[\"C_x\"] = StuntDF.groupby([\"gameId\", \"playId\"])[\"C_x\"].fillna(method=\"ffill\")\n",
    "StuntDF[\"C_y\"] = StuntDF.groupby([\"gameId\", \"playId\"])[\"C_y\"].fillna(method=\"ffill\")\n",
    "StuntDF[\"C_adjusted_x\"] = StuntDF[\"clean_x\"] - StuntDF[\"C_x\"]\n",
    "StuntDF[\"C_adjusted_y\"] = StuntDF[\"clean_y\"] - StuntDF[\"C_y\"]\n",
    "\n",
    "\n",
    "GapDF = StuntDF[\n",
    "    (StuntDF[\"pff_role\"] == \"Block\")\n",
    "    & (\n",
    "        StuntDF[\"pff_positionLinedUp\"].isin(\n",
    "            [\"LT\", \"LG\", \"C\", \"RG\", \"RT\", \"TE-L\", \"TE-R\"]\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "# Creating a wider dataset with the y positions for each OL position as a new column\n",
    "StuntWider = GapDF.pivot_table(\n",
    "    index=[\"gameId\", \"playId\", \"frameId\"], columns=\"pff_positionLinedUp\", values=\"C_adjusted_y\"\n",
    ").reset_index()\n",
    "\n",
    "# Filling the missing data for TEs to help aid assignment later\n",
    "StuntWider[\"TE-L\"] = StuntWider[\"TE-L\"].fillna(100)\n",
    "StuntWider[\"TE-R\"] = StuntWider[\"TE-R\"].fillna(0)\n",
    "\n",
    "# Making a new dataframe that is just the pass rushers\n",
    "Starting_Gaps = StuntDF[(StuntDF[\"pff_role\"] == \"Rush\")]\n",
    "\n",
    "# Create Cutoff Point into the play\n",
    "Time_Cutoff = 20\n",
    "\n",
    "Starting_Gaps[\"Cutoff_Point\"] = np.where(\n",
    "    Starting_Gaps[\"end_frame\"] < Starting_Gaps[\"start_frame\"] + Time_Cutoff,\n",
    "    Starting_Gaps[\"end_frame\"],\n",
    "    Starting_Gaps[\"start_frame\"] + Time_Cutoff,\n",
    ")\n",
    "\n",
    "Starting_Gaps = Starting_Gaps[\n",
    "    (Starting_Gaps[\"frameId\"] >= Starting_Gaps[\"start_frame\"])\n",
    "    & (Starting_Gaps[\"frameId\"] <= Starting_Gaps[\"Cutoff_Point\"])\n",
    "]\n",
    "\n",
    "# Joining the OL Y positional data onto the Starting_Gaps df\n",
    "Starting_Gaps = pd.merge(Starting_Gaps, StuntWider, on=[\"gameId\", \"playId\", \"frameId\"])\n",
    "\n",
    "# Assigning the Gaps based on y position data\n",
    "conditions = [\n",
    "    Starting_Gaps[\"C_adjusted_y\"] > Starting_Gaps[\"TE-L\"],\n",
    "    (Starting_Gaps[\"C_adjusted_y\"] < Starting_Gaps[\"TE-L\"])\n",
    "    & (Starting_Gaps[\"C_adjusted_y\"] > Starting_Gaps[\"LT\"]),\n",
    "    (Starting_Gaps[\"C_adjusted_y\"] < Starting_Gaps[\"LT\"])\n",
    "    & (Starting_Gaps[\"C_adjusted_y\"] > Starting_Gaps[\"LG\"]),\n",
    "    (Starting_Gaps[\"C_adjusted_y\"] < Starting_Gaps[\"LG\"])\n",
    "    & (Starting_Gaps[\"C_adjusted_y\"] > Starting_Gaps[\"C\"]),\n",
    "    (Starting_Gaps[\"C_adjusted_y\"] < Starting_Gaps[\"C\"])\n",
    "    & (Starting_Gaps[\"C_adjusted_y\"] > Starting_Gaps[\"RG\"]),\n",
    "    (Starting_Gaps[\"C_adjusted_y\"] < Starting_Gaps[\"RG\"])\n",
    "    & (Starting_Gaps[\"C_adjusted_y\"] > Starting_Gaps[\"RT\"]),\n",
    "    (Starting_Gaps[\"C_adjusted_y\"] < Starting_Gaps[\"RT\"])\n",
    "    & (Starting_Gaps[\"C_adjusted_y\"] > Starting_Gaps[\"TE-R\"]),\n",
    "    Starting_Gaps[\"C_adjusted_y\"] < Starting_Gaps[\"TE-R\"],\n",
    "]\n",
    "choices = [\"L-D\", \"L-C\", \"L-B\", \"L-A\", \"R-A\", \"R-B\", \"R-C\", \"R-D\"]\n",
    "\n",
    "Starting_Gaps[\"Gap_Assignment\"] = np.select(conditions, choices, default=np.NAN)\n",
    "\n",
    "# Filling any NAN Gaps (which occur when the DL is directly on the OL Y value) with their previous Gap Assignment\n",
    "Starting_Gaps[\"Gap_Assignment\"] = Starting_Gaps.groupby([\"gameId\", \"playId\"])[\n",
    "    \"Gap_Assignment\"\n",
    "].fillna(method=\"ffill\")\n",
    "\n",
    "\n",
    "Start_Gap = Starting_Gaps[Starting_Gaps[\"frameId\"] == Starting_Gaps[\"start_frame\"]].groupby([\"gameId\", \"playId\", \"nflId\"])[[\"gameId\", \"playId\", \"nflId\",\"Gap_Assignment\"]].transform('first')\n",
    "End_Gap = Starting_Gaps[Starting_Gaps[\"frameId\"] == Starting_Gaps[\"end_frame\"]].groupby([\"gameId\", \"playId\", \"nflId\"])[[\"gameId\", \"playId\", \"nflId\",\"Gap_Assignment\"]].transform('first')\n",
    "\n",
    "Starting_Gaps = pd.merge(Starting_Gaps, Start_Gap, on=[\"gameId\", \"playId\", \"nflId\"])\n",
    "Starting_Gaps = pd.merge(Starting_Gaps, End_Gap, on=[\"gameId\", \"playId\", \"nflId\"])\n",
    "\n",
    "Starting_Gaps['RushPath'] = Starting_Gaps['Gap_Assignment_y'] + '-' + Starting_Gaps['Gap_Assignment'].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a One Hot Encoding for the Rush Paths types on a given play\n",
    "RushPaths = Starting_Gaps.copy()\n",
    "\n",
    "RushPaths = RushPaths.pivot_table(\n",
    "    index=[\"gameId\", \"playId\"], columns = \"RushPath\", values=\"frameId\"\n",
    ").reset_index()\n",
    "\n",
    "exclude_columns = [\"gameId\", \"playId\"]\n",
    "\n",
    "RushPaths.loc[:, ~RushPaths.columns.isin(exclude_columns)] = RushPaths.loc[:, ~RushPaths.columns.isin(exclude_columns)].notna().replace(True, 1)\n",
    "RushPaths = RushPaths.replace(False, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Number of Rushers on a play\n",
    "Rushers = Starting_Gaps.copy()\n",
    "\n",
    "Rushers = Rushers.groupby(['gameId', 'playId', 'nflId']) \\\n",
    "                  .head(1) \\\n",
    "                  .assign(Rushers=lambda x: x.groupby(['gameId', 'playId'])['gameId'].transform('count'))\n",
    "\n",
    "Rushers = Rushers[[\"gameId\", \"playId\", \"Rushers\"]].drop_duplicates()\n",
    "\n",
    "#Creating Number of Blockers on a play\n",
    "Blockers = StuntDF.copy()\n",
    "\n",
    "Blockers = Blockers[Blockers[\"pff_role\"] == \"Block\"].groupby(['gameId', 'playId', 'nflId']) \\\n",
    "                  .head(1) \\\n",
    "                  .assign(Blockers=lambda x: x.groupby(['gameId', 'playId'])['gameId'].transform('count'))\n",
    "\n",
    "Blockers = Blockers[[\"gameId\", \"playId\", \"Blockers\"]].drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sethl\\AppData\\Local\\Temp\\ipykernel_9208\\2451781383.py:10: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  Positions.loc[:, ~Positions.columns.isin(exclude_columns)] = Positions.loc[:, ~Positions.columns.isin(exclude_columns)].notna().replace(True, 1)\n"
     ]
    }
   ],
   "source": [
    "#Creating a One-Hot Encoding for the positions on a given play\n",
    "Positions = StuntDF.copy()\n",
    "\n",
    "Positions = Positions.pivot_table(\n",
    "    index=[\"gameId\", \"playId\"], columns = \"pff_positionLinedUp\", values=\"frameId\"\n",
    ").reset_index()\n",
    "\n",
    "exclude_columns = [\"gameId\", \"playId\"]\n",
    "\n",
    "Positions.loc[:, ~Positions.columns.isin(exclude_columns)] = Positions.loc[:, ~Positions.columns.isin(exclude_columns)].notna().replace(True, 1)\n",
    "Positions = Positions.replace(False, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a One Hot Encoding for the Block types on a given play\n",
    "BlockTypes = StuntDF.copy()\n",
    "\n",
    "BlockTypes = BlockTypes.pivot_table(\n",
    "    index=[\"gameId\", \"playId\"], columns = \"pff_blockType\", values=\"frameId\"\n",
    ").reset_index()\n",
    "\n",
    "exclude_columns = [\"gameId\", \"playId\"]\n",
    "\n",
    "BlockTypes.loc[:, ~BlockTypes.columns.isin(exclude_columns)] = BlockTypes.loc[:, ~BlockTypes.columns.isin(exclude_columns)].notna().replace(True, 1)\n",
    "BlockTypes = BlockTypes.replace(False, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "man_zone_encoding = pd.get_dummies(man_zone, columns=['pff_passCoverage', 'pff_passCoverageType'])\n",
    "\n",
    "play_encoding = pd.get_dummies(play_info, columns=[\"offenseFormation\", \"personnelO\", \"personnelD\", \"defendersInBox\", \"dropBackType\", \"pff_playAction\"])\n",
    "\n",
    "Center_LOC = pff_scouting_data[[\"gameId\", \"playId\", \"nflId\", \"pff_positionLinedUp\"]]\n",
    "\n",
    "# Filtering the WorkDF down to just the blockers\n",
    "C_AdjustedDF = pd.merge(\n",
    "    WorkDF, Center_LOC, on=[\"gameId\", \"playId\", \"nflId\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Making Center Adjusted Coordinates for every player\n",
    "C_AdjustedDF = C_AdjustedDF.sort_values(by=[\"gameId\", \"playId\", \"frameId\", \"pff_positionLinedUp\"])\n",
    "first_frame = C_AdjustedDF[C_AdjustedDF[\"pff_positionLinedUp\"] == \"C\"].groupby([\"gameId\", \"playId\"]).transform(\"first\")\n",
    "C_AdjustedDF[\"C_x\"] = first_frame[\"clean_x\"]\n",
    "C_AdjustedDF[\"C_y\"] = first_frame[\"clean_y\"]\n",
    "C_AdjustedDF[\"C_x\"] = C_AdjustedDF.groupby([\"gameId\", \"playId\"])[\"C_x\"].fillna(method=\"ffill\")\n",
    "C_AdjustedDF[\"C_y\"] = C_AdjustedDF.groupby([\"gameId\", \"playId\"])[\"C_y\"].fillna(method=\"ffill\")\n",
    "C_AdjustedDF[\"C_adjusted_x\"] = C_AdjustedDF[\"clean_x\"] - C_AdjustedDF[\"C_x\"]\n",
    "C_AdjustedDF[\"C_adjusted_y\"] = C_AdjustedDF[\"clean_y\"] - C_AdjustedDF[\"C_y\"]\n",
    "\n",
    "C_AdjustedDF = C_AdjustedDF[[\"gameId\", \"playId\", \"nflId\", \"frameId\", \"C_adjusted_x\", \"C_adjusted_y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_AdjustedDF.to_csv(\"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Created_DF/C_AdjustedDF.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "RoutesDf = pd.merge(\n",
    "    WorkDF, play_route_coverage, on=[\"gameId\", \"playId\", \"nflId\"], how=\"inner\"\n",
    ")\n",
    "\n",
    "ClusterDF = RoutesDf[[\"gameId\", \"playId\"]].drop_duplicates()\n",
    "\n",
    "ClusterDF = pd.merge(ClusterDF, man_zone_encoding, on=[\"gameId\", \"playId\"])\n",
    "ClusterDF = pd.merge(ClusterDF, play_encoding, on=[\"gameId\", \"playId\"])\n",
    "ClusterDF = pd.merge(ClusterDF, Rushers, on=[\"gameId\", \"playId\"])\n",
    "ClusterDF = pd.merge(ClusterDF, Blockers, on=[\"gameId\", \"playId\"])\n",
    "ClusterDF = pd.merge(ClusterDF, Positions, on=[\"gameId\", \"playId\"])\n",
    "ClusterDF = pd.merge(ClusterDF, RushPaths, on=[\"gameId\", \"playId\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sethl\\anaconda3\\envs\\S52\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=100)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=100)  # Replace 3 with your chosen K value\n",
    "kmeans.fit(ClusterDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClusterDF['Cluster'] = kmeans.labels_\n",
    "\n",
    "FinalClusterJoin = ClusterDF[[\"gameId\", \"playId\", \"Cluster\"]]\n",
    "\n",
    "ClusterDF.to_csv(\"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Created_DF/ClusterDF.csv\", index=False)\n",
    "RoutesDf.to_csv(\"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Created_DF/RoutesDf.csv\", index=False)\n",
    "\n",
    "#Starting_Gaps.to_csv(\"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Created_DF/Starting_Gaps.csv\", index=False)\n",
    "StuntDF.to_csv(\"C:/Users/sethl/OneDrive/Important Stuff/R/R files/NFL/DataBowl/2024-Big-Data-Bowl/Created_DF/StuntDF.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S52",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
