{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the relative path to the data directory\n",
    "data_folder_path = \"insert path\"\n",
    "\n",
    "# List all files in the data folder\n",
    "file_list = os.listdir(data_folder_path)\n",
    "\n",
    "# Use glob to filter specific file types\n",
    "csv_files = glob.glob(os.path.join(data_folder_path, \"*.csv\"))\n",
    "\n",
    "# Read in the weekly game data and concat into one combined df\n",
    "dfs = [pd.read_csv(file) for file in csv_files]\n",
    "combined_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the relative path to the data directory\n",
    "non_games_data_folder_path = \"insert path\"\n",
    "\n",
    "# List all files in the data folder\n",
    "file_list_non_games = os.listdir(non_games_data_folder_path)\n",
    "\n",
    "# Use glob to filter specific file types\n",
    "csv_files_non_games = glob.glob(os.path.join(non_games_data_folder_path, \"*.csv\"))\n",
    "\n",
    "\n",
    "# Read in the supplementary data\n",
    "games = pd.read_csv(csv_files_non_games[0])\n",
    "nfl_colors = pd.read_csv(csv_files_non_games[1])\n",
    "players = pd.read_csv(csv_files_non_games[2])\n",
    "plays = pd.read_csv(csv_files_non_games[3])\n",
    "tackles = pd.read_csv(csv_files_non_games[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clean_df = pd.read_csv(\"insert path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the orientation of the plays\n",
    "clean_df = combined_df.copy()\n",
    "\n",
    "clean_df['clean_x'] = clean_df.apply(lambda row: 120 - row['x'] if row['playDirection'] == \"left\" else row['x'], axis=1)\n",
    "clean_df['clean_y'] = clean_df.apply(lambda row: 160 / 3 - row['y'] if row['playDirection'] == \"left\" else row['y'], axis=1)\n",
    "clean_df['clean_dir'] = clean_df.apply(lambda row: row['dir'] + 180 if row['playDirection'] == \"left\" else row['dir'], axis=1)\n",
    "clean_df['clean_dir'] = clean_df['clean_dir'].apply(lambda val: val - 360 if val > 360 else val)\n",
    "clean_df['clean_o'] = clean_df.apply(lambda row: row['o'] + 180 if row['playDirection'] == \"left\" else row['o'], axis=1)\n",
    "clean_df['clean_o'] = clean_df['clean_o'].apply(lambda val: val - 360 if val > 360 else val)\n",
    "\n",
    "\n",
    "# Merge nfl_colors and change the color of the football\n",
    "clean_df = pd.merge(clean_df, nfl_colors, left_on=\"club\", right_on=\"Code\", how=\"left\")\n",
    "clean_df[\"primary\"] = np.where(\n",
    "    clean_df[\"primary\"].isna(), \"#8b4513\", clean_df[\"primary\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv(\"insert path\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_df[\"event\"].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutate 'df'\n",
    "filtered_df = clean_df.copy()\n",
    "\n",
    "filtered_df[\"is_start\"] = np.where(\n",
    "    filtered_df[\"event\"].isin(\n",
    "        [\n",
    "            \"autoevent_ballsnap\",\n",
    "              \"ball_snap\",\n",
    "                \"pass_arrived\",\n",
    "                  \"pass_outcome_caught\",\n",
    "                  \"pass_outcome_touchdown\",\n",
    "                    \"run\",\n",
    "                      \"snap_direct\",\n",
    "                      \"handoff\"\n",
    "    ]), 1, 0\n",
    ")\n",
    "filtered_df[\"is_end\"] = np.where(\n",
    "    filtered_df[\"event\"].isin(\n",
    "        [\n",
    "            \"tackle\",\n",
    "            \"touchdown\",\n",
    "            \"out_of_bounds\",\n",
    "            \"fumble\",\n",
    "            \"lateral\",\n",
    "            \"qb_sack\",\n",
    "            \"autoevent_passinterrupted\",\n",
    "            \"safety\",\n",
    "            \"autoevent_passinterrupted\"\n",
    "        ]\n",
    "    ),\n",
    "    1,\n",
    "    0,\n",
    ")\n",
    "# Group by and mutate 'df'\n",
    "grouped = filtered_df.groupby([\"gameId\", \"playId\"])\n",
    "filtered_df[\"any_start\"] = grouped[\"is_start\"].transform(\"any\")\n",
    "filtered_df[\"any_end\"] = grouped[\"is_end\"].transform(\"any\")\n",
    "\n",
    "# Filter and summarize 'df'\n",
    "intermediate_df = filtered_df[(filtered_df[\"any_start\"]) & (filtered_df[\"any_end\"])]\n",
    "\n",
    "\n",
    "# Define a function to calculate start_frame and end_frame\n",
    "def calculate_frames(group):\n",
    "    start_indices = group[group[\"is_start\"] == 1].index\n",
    "    if len(start_indices) == 0:\n",
    "        return pd.Series({\"start_frame\": None, \"end_frame\": None})\n",
    "\n",
    "    start_frame = group.loc[start_indices[0], \"frameId\"]\n",
    "\n",
    "    end_indices = group[(group[\"is_end\"] == 1) & (group[\"frameId\"] > start_frame)].index\n",
    "    if len(end_indices) == 0:\n",
    "        last_row_index = group.index[-1]  # Get the index of the last row in the group\n",
    "        end_frame = group.loc[last_row_index, \"frameId\"]\n",
    "    else:\n",
    "        end_frame = group.loc[end_indices[0], \"frameId\"]\n",
    "\n",
    "    return pd.Series({\"start_frame\": start_frame, \"end_frame\": end_frame})\n",
    "\n",
    "\n",
    "# Apply the function to each group and reset index\n",
    "frames_of_interest = (\n",
    "    intermediate_df.groupby([\"gameId\", \"playId\"]).apply(calculate_frames).reset_index()\n",
    ")\n",
    "\n",
    "GotTheBall = plays[[\"gameId\", \"playId\", \"ballCarrierId\"]]\n",
    "GotTheBall[\"GotTheBall\"] = 1\n",
    "\n",
    "\n",
    "filtered_df[\"Pass\"] = np.where(\n",
    "    filtered_df[\"event\"].isin(\n",
    "        [\n",
    "             \"pass_arrived\",\n",
    "                  \"pass_outcome_caught\",\n",
    "                  \"pass_outcome_touchdown\"\n",
    "    ]), 1, 0\n",
    ")\n",
    "\n",
    "filtered_df['PassPlay'] = filtered_df.groupby(['gameId', 'playId'])['Pass'].transform('max')\n",
    "\n",
    "PassPlay = filtered_df[['gameId', 'playId', 'PassPlay']].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a WorkDF that is filtered down to just the frames of interest\n",
    "WorkDF = pd.merge(clean_df, frames_of_interest, on=[\"gameId\", \"playId\"], how=\"inner\")\n",
    "WorkDF = WorkDF[\n",
    "    (WorkDF[\"frameId\"] >= WorkDF[\"start_frame\"])\n",
    "    & (WorkDF[\"frameId\"] <= WorkDF[\"end_frame\"])\n",
    "]\n",
    "\n",
    "WorkDF = pd.merge(WorkDF, GotTheBall,\n",
    "                   left_on = [\"gameId\", \"playId\", \"nflId\"],\n",
    "                   right_on=[\"gameId\", \"playId\", \"ballCarrierId\"],\n",
    "                   how = \"left\")\n",
    "\n",
    "\n",
    "WorkDF = pd.merge(WorkDF, PassPlay,\n",
    "                   on = [\"gameId\", \"playId\"],\n",
    "                   how = \"left\")\n",
    "\n",
    "\n",
    "WorkDF = WorkDF[(WorkDF[\"club\"] != \"football\")]\n",
    "\n",
    "WorkDF['area'] = np.nan\n",
    "\n",
    "WorkDF['Time'] = WorkDF.groupby(['gameId', 'playId'])['frameId'].transform(lambda x: x - x.min() + 1)\n",
    "\n",
    "WorkDF.fillna(0, inplace=True)\n",
    "\n",
    "# Calculate the maximum absolute value in the column\n",
    "max_abs_value = WorkDF[WorkDF[\"GotTheBall\"] == 1]['a'].abs().max()\n",
    "\n",
    "# Calculate the percent rank based on scaled absolute values\n",
    "WorkDF['PercentRankA'] = (WorkDF['a'].abs() / max_abs_value)\n",
    "\n",
    "WorkDF = pd.merge(WorkDF, plays, on = [\"gameId\", \"playId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamesGroup = WorkDF.groupby(\"gameId\")\n",
    "\n",
    "\n",
    "for gameName, game in gamesGroup: \n",
    "\n",
    "    vor_filepath = \"insert path\"\n",
    "    \n",
    "    vor_filename = f\"WorkDF{gameName}.csv\"\n",
    "    \n",
    "    # Save the processed chunk to a specific location\n",
    "    game.to_csv(f\"{vor_filepath}{vor_filename}\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WorkDF.to_csv(\"insert path\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S52",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
